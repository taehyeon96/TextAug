{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f37284c",
   "metadata": {},
   "source": [
    "https://github.com/varinf/TransformersDataAugmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd1c33",
   "metadata": {},
   "source": [
    "### 작업 경로확인 및 git clone (ok) - clone 다시할 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6345160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d013ab2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'(Hyeong)DM_Assignment_2 (1).ipynb'   TransformersDataAugmentation\r\n",
      " 210412_datamining_HW2\t\t      apex\r\n",
      " DM_HW2_120210203.ipynb\t\t      datasets\r\n",
      " Dacon_2021\t\t\t      pinSageEX1.ipynb\r\n",
      " Datamining_HW3\t\t\t      pinSage_dglEX\r\n",
      " NLP\t\t\t\t      start_with_server_210522.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcfbbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TransformersDataAugmentation'에 복제합니다...\n",
      "remote: Enumerating objects: 49, done.\u001b[K\n",
      "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
      "remote: Total 49 (delta 12), reused 38 (delta 8), pack-reused 0\u001b[K\n",
      "오브젝트 묶음 푸는 중: 100% (49/49), 완료.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/varinf/TransformersDataAugmentation.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58768c48",
   "metadata": {},
   "source": [
    "### bash해서 스크립트파일 실행 (ok) - 다시할 필요 없음\n",
    "- 방법1) 반드시 경로를 src/utils까지 이동한 후 할것\n",
    "- 방법2) 아니면 bash할 때 경로지정을 해주거나\n",
    "- 방법3) 경로를 src/utils까지 이동하되, .sh파일에서 저장될 dataset의 경로만 수정해줄것\n",
    "-\n",
    "- 나는 일단 방법1을 사용해서 src/utils에 dataset폴더 및 데이터셋들을 넣었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "292eaa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils\n"
     ]
    }
   ],
   "source": [
    "%cd TransformersDataAugmentation/src/utils/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "967602d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-22 18:51:33--  https://raw.githubusercontent.com/1024er/cbert_aug/crayon/datasets/TREC/train.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 268193 (262K) [text/plain]\n",
      "Saving to: ‘datasets/trec/train.raw’\n",
      "\n",
      "datasets/trec/train 100%[===================>] 261.91K  1.40MB/s    in 0.2s    \n",
      "\n",
      "2021-05-22 18:51:34 (1.40 MB/s) - ‘datasets/trec/train.raw’ saved [268193/268193]\n",
      "\n",
      "--2021-05-22 18:51:34--  https://raw.githubusercontent.com/1024er/cbert_aug/crayon/datasets/TREC/dev.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29692 (29K) [text/plain]\n",
      "Saving to: ‘datasets/trec/dev.raw’\n",
      "\n",
      "datasets/trec/dev.r 100%[===================>]  29.00K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2021-05-22 18:51:35 (2.02 MB/s) - ‘datasets/trec/dev.raw’ saved [29692/29692]\n",
      "\n",
      "--2021-05-22 18:51:35--  https://raw.githubusercontent.com/1024er/cbert_aug/crayon/datasets/TREC/test.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19995 (20K) [text/plain]\n",
      "Saving to: ‘datasets/trec/test.raw’\n",
      "\n",
      "datasets/trec/test. 100%[===================>]  19.53K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2021-05-22 18:51:35 (2.26 MB/s) - ‘datasets/trec/test.raw’ saved [19995/19995]\n",
      "\n",
      "--2021-05-22 18:51:36--  https://raw.githubusercontent.com/1024er/cbert_aug/crayon/datasets/stsa.binary/train.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 670802 (655K) [text/plain]\n",
      "Saving to: ‘datasets/stsa/train.raw’\n",
      "\n",
      "datasets/stsa/train 100%[===================>] 655.08K  2.25MB/s    in 0.3s    \n",
      "\n",
      "2021-05-22 18:51:37 (2.25 MB/s) - ‘datasets/stsa/train.raw’ saved [670802/670802]\n",
      "\n",
      "--2021-05-22 18:51:37--  https://raw.githubusercontent.com/1024er/cbert_aug/crayon/datasets/stsa.binary/dev.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 74994 (73K) [text/plain]\n",
      "Saving to: ‘datasets/stsa/dev.raw’\n",
      "\n",
      "datasets/stsa/dev.r 100%[===================>]  73.24K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2021-05-22 18:51:37 (973 KB/s) - ‘datasets/stsa/dev.raw’ saved [74994/74994]\n",
      "\n",
      "--2021-05-22 18:51:37--  https://raw.githubusercontent.com/1024er/cbert_aug/crayon/datasets/stsa.binary/test.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 195399 (191K) [text/plain]\n",
      "Saving to: ‘datasets/stsa/test.raw’\n",
      "\n",
      "datasets/stsa/test. 100%[===================>] 190.82K  1.22MB/s    in 0.2s    \n",
      "\n",
      "2021-05-22 18:51:38 (1.22 MB/s) - ‘datasets/stsa/test.raw’ saved [195399/195399]\n",
      "\n",
      "--2021-05-22 18:51:38--  https://raw.githubusercontent.com/MiuLab/SlotGated-SLU/master/data/snips/train/seq.in\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 617079 (603K) [text/plain]\n",
      "Saving to: ‘datasets/snips/train.seq’\n",
      "\n",
      "datasets/snips/trai 100%[===================>] 602.62K  2.29MB/s    in 0.3s    \n",
      "\n",
      "2021-05-22 18:51:40 (2.29 MB/s) - ‘datasets/snips/train.seq’ saved [617079/617079]\n",
      "\n",
      "--2021-05-22 18:51:40--  https://raw.githubusercontent.com/MiuLab/SlotGated-SLU/master/data/snips/train/label\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 184532 (180K) [text/plain]\n",
      "Saving to: ‘datasets/snips/train.label’\n",
      "\n",
      "datasets/snips/trai 100%[===================>] 180.21K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-05-22 18:51:41 (1.24 MB/s) - ‘datasets/snips/train.label’ saved [184532/184532]\n",
      "\n",
      "--2021-05-22 18:51:41--  https://raw.githubusercontent.com/MiuLab/SlotGated-SLU/master/data/snips/valid/seq.in\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33629 (33K) [text/plain]\n",
      "Saving to: ‘datasets/snips/valid.seq’\n",
      "\n",
      "datasets/snips/vali 100%[===================>]  32.84K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2021-05-22 18:51:42 (1.65 MB/s) - ‘datasets/snips/valid.seq’ saved [33629/33629]\n",
      "\n",
      "--2021-05-22 18:51:42--  https://raw.githubusercontent.com/MiuLab/SlotGated-SLU/master/data/snips/valid/label\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9900 (9.7K) [text/plain]\n",
      "Saving to: ‘datasets/snips/valid.label’\n",
      "\n",
      "datasets/snips/vali 100%[===================>]   9.67K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-05-22 18:51:42 (30.4 MB/s) - ‘datasets/snips/valid.label’ saved [9900/9900]\n",
      "\n",
      "--2021-05-22 18:51:42--  https://raw.githubusercontent.com/MiuLab/SlotGated-SLU/master/data/snips/test/seq.in\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33121 (32K) [text/plain]\n",
      "Saving to: ‘datasets/snips/test.seq’\n",
      "\n",
      "datasets/snips/test 100%[===================>]  32.34K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2021-05-22 18:51:43 (1.75 MB/s) - ‘datasets/snips/test.seq’ saved [33121/33121]\n",
      "\n",
      "--2021-05-22 18:51:43--  https://raw.githubusercontent.com/MiuLab/SlotGated-SLU/master/data/snips/test/label\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10120 (9.9K) [text/plain]\n",
      "Saving to: ‘datasets/snips/test.label’\n",
      "\n",
      "datasets/snips/test 100%[===================>]   9.88K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2021-05-22 18:51:44 (11.0 MB/s) - ‘datasets/snips/test.label’ saved [10120/10120]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash download_and_prepare_datasets.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22d37b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8524183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode/TransformersDataAugmentation\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074762e",
   "metadata": {},
   "source": [
    "### 필요 모듈 설치 - 다시할 필요 없고, 버전확인코드만 실행시켜볼것\n",
    "### -> cmd화면에서 설치했으며, 이것은 jupyter에서 실행하는 방법 알아두기만 하는 정도로\n",
    "- pytorch 1.5 (ok)\n",
    "- fairseq 9.0 (ok)\n",
    "- transformers 2.9 (ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bfd767d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.5.0+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (703.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 703.8 MB 99 kB/s  eta 0:00:01     |████████████▊                   | 278.7 MB 8.5 MB/s eta 0:00:50     |█████████████▌                  | 297.6 MB 8.5 MB/s eta 0:00:48     |██████████████▉                 | 325.3 MB 9.0 MB/s eta 0:00:43     |████████████████████████▉       | 547.4 MB 7.8 MB/s eta 0:00:21     |█████████████████████████▊      | 565.9 MB 7.3 MB/s eta 0:00:19     |██████████████████████████▍     | 580.2 MB 8.4 MB/s eta 0:00:15\n",
      "\u001b[?25hCollecting torchvision==0.6.0+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from torch==1.5.0+cu101) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from torch==1.5.0+cu101) (1.20.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from torchvision==0.6.0+cu101) (8.2.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1\n",
      "    Uninstalling torch-1.8.1:\n",
      "      Successfully uninstalled torch-1.8.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.8.2\n",
      "    Uninstalling torchvision-0.8.2:\n",
      "      Successfully uninstalled torchvision-0.8.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.8.1 requires torch==1.8.1, but you have torch 1.5.0+cu101 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.5.0 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a14f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2e9f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq==0.9\n",
      "  Using cached fairseq-0.9.0.tar.gz (306 kB)\n",
      "Requirement already satisfied: cffi in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from fairseq==0.9) (1.14.0)\n",
      "Collecting cython\n",
      "  Using cached Cython-0.29.23-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: numpy in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from fairseq==0.9) (1.20.1)\n",
      "Requirement already satisfied: regex in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from fairseq==0.9) (2020.11.13)\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: torch in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from fairseq==0.9) (1.5.0+cu101)\n",
      "Requirement already satisfied: tqdm in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from fairseq==0.9) (4.42.1)\n",
      "Requirement already satisfied: pycparser in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from cffi->fairseq==0.9) (2.20)\n",
      "Collecting portalocker==2.0.0\n",
      "  Using cached portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: future in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from torch->fairseq==0.9) (0.18.2)\n",
      "Building wheels for collected packages: fairseq\n",
      "  Building wheel for fairseq (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/user/anaconda3/envs/hs/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-w6u8hebd\n",
      "       cwd: /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/\n",
      "  Complete output (278 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.7\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  copying fairseq_cli/interactive.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  copying fairseq_cli/train.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  copying fairseq_cli/generate.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  copying fairseq_cli/__init__.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  copying fairseq_cli/setup.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  copying fairseq_cli/eval_lm.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  copying fairseq_cli/preprocess.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  copying fairseq_cli/score.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "  creating build/lib.linux-x86_64-3.7/examples\n",
      "  copying examples/__init__.py -> build/lib.linux-x86_64-3.7/examples\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/file_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/trainer.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/registry.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/progress_bar.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/distributed_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/search.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/pdb.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/options.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/bleu.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/binarizer.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/__init__.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/meters.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/checkpoint_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/legacy_distributed_data_parallel.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/iterative_refinement_generator.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  copying fairseq/hub_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "  creating build/lib.linux-x86_64-3.7/examples/speech_recognition\n",
      "  copying examples/speech_recognition/infer.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition\n",
      "  copying examples/speech_recognition/w2l_decoder.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition\n",
      "  copying examples/speech_recognition/__init__.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition\n",
      "  creating build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  copying examples/noisychannel/rerank_options.py -> build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  copying examples/noisychannel/rerank_generate.py -> build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  copying examples/noisychannel/__init__.py -> build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  copying examples/noisychannel/rerank.py -> build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  copying examples/noisychannel/rerank_tune.py -> build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  copying examples/noisychannel/rerank_score_lm.py -> build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  copying examples/noisychannel/rerank_utils.py -> build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  copying examples/noisychannel/rerank_score_bw.py -> build/lib.linux-x86_64-3.7/examples/noisychannel\n",
      "  creating build/lib.linux-x86_64-3.7/examples/speech_recognition/tasks\n",
      "  copying examples/speech_recognition/tasks/__init__.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/tasks\n",
      "  copying examples/speech_recognition/tasks/speech_recognition.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/tasks\n",
      "  creating build/lib.linux-x86_64-3.7/examples/speech_recognition/criterions\n",
      "  copying examples/speech_recognition/criterions/ASG_loss.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/criterions\n",
      "  copying examples/speech_recognition/criterions/cross_entropy_acc.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/criterions\n",
      "  copying examples/speech_recognition/criterions/CTC_loss.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/criterions\n",
      "  copying examples/speech_recognition/criterions/__init__.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/criterions\n",
      "  creating build/lib.linux-x86_64-3.7/examples/speech_recognition/data\n",
      "  copying examples/speech_recognition/data/collaters.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/data\n",
      "  copying examples/speech_recognition/data/__init__.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/data\n",
      "  copying examples/speech_recognition/data/replabels.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/data\n",
      "  copying examples/speech_recognition/data/asr_dataset.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/data\n",
      "  copying examples/speech_recognition/data/data_utils.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/data\n",
      "  creating build/lib.linux-x86_64-3.7/examples/speech_recognition/models\n",
      "  copying examples/speech_recognition/models/vggtransformer.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/models\n",
      "  copying examples/speech_recognition/models/w2l_conv_glu_enc.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/models\n",
      "  copying examples/speech_recognition/models/__init__.py -> build/lib.linux-x86_64-3.7/examples/speech_recognition/models\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/transformer_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/positional_embedding.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/adaptive_input.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/vggblock.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/gelu.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/lightweight_convolution.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/mean_pool_gating_network.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/transformer_sentence_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/sparse_transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/sparse_multihead_attention.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/sparse_transformer_sentence_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/dynamic_convolution.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/layer_norm.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/unfold.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/logsumexp_moe.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/character_token_embedder.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/highway.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/cross_lingual_lm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/translation_lev.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/translation_moe.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/sentence_prediction.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/audio_pretraining.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/multilingual_masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/denoising.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/multilingual_translation.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/sentence_ranking.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/semisupervised_translation.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/legacy_masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  copying fairseq/tasks/translation_from_pretrained_xlm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/nat_loss.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/sentence_prediction.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/sentence_ranking.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/binary_cross_entropy.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/legacy_masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  copying fairseq/criterions/composite_loss.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/strip_token_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/sharded_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/concat_sentences_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/truncate_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/id_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/plasma_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/lru_cache_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/resampling_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/nested_dictionary_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/colorize_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/round_robin_zip_datasets.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/noising.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/lm_context_window_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/base_wrapper_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/sort_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/multi_corpus_sampled_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/subsample_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/mask_tokens_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/raw_label_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/iterators.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/offset_tokens_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/num_samples_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/append_token_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/denoising_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/pad_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/transform_eos_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/list_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/prepend_token_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/replace_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/transform_eos_lang_pair_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/prepend_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/concat_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/roll_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/backtranslation_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/numel_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/adadelta.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/adamax.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/bmuf.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/adafactor.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/nag.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  copying fairseq/optim/adam.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/insertion_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/iterative_nonautoregressive_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/lstm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/transformer_from_pretrained_xlm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/lightconv.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/model_utils.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/fconv.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/distributed_fairseq_model.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/nonautoregressive_ensembles.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/nonautoregressive_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/transformer_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/fconv_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/lightconv_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/cmlm_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/levenshtein_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/multilingual_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  copying fairseq/models/wav2vec.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "  copying fairseq/modules/dynamicconv_layer/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "  copying fairseq/modules/dynamicconv_layer/setup.py -> build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "  copying fairseq/modules/dynamicconv_layer/dynamicconv_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "  copying fairseq/modules/dynamicconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "  copying fairseq/modules/lightconv_layer/lightconv_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "  copying fairseq/modules/lightconv_layer/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "  copying fairseq/modules/lightconv_layer/setup.py -> build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "  copying fairseq/modules/lightconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "  copying fairseq/data/legacy/masked_lm_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "  copying fairseq/data/legacy/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "  copying fairseq/data/legacy/block_pair_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "  copying fairseq/data/legacy/masked_lm_dictionary.py -> build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/data/audio\n",
      "  copying fairseq/data/audio/raw_audio_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio\n",
      "  copying fairseq/data/audio/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/space_tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/nltk_tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/sentencepiece_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/subword_nmt_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/gpt2_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/moses_tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/gpt2_bpe_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/hf_bert_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/fastbpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  copying fairseq/data/encoders/utils.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/polynomial_decay_schedule.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/triangular_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  copying fairseq/optim/lr_scheduler/cosine_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "  copying fairseq/models/roberta/hub_interface.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "  copying fairseq/models/roberta/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "  copying fairseq/models/roberta/model.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "  copying fairseq/models/roberta/alignment_utils.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "  creating build/lib.linux-x86_64-3.7/fairseq/models/bart\n",
      "  copying fairseq/models/bart/hub_interface.py -> build/lib.linux-x86_64-3.7/fairseq/models/bart\n",
      "  copying fairseq/models/bart/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models/bart\n",
      "  copying fairseq/models/bart/model.py -> build/lib.linux-x86_64-3.7/fairseq/models/bart\n",
      "  running build_ext\n",
      "  building 'fairseq.libbleu' extension\n",
      "  creating /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7\n",
      "  creating /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq\n",
      "  creating /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq/clib\n",
      "  creating /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu\n",
      "  Emitting ninja build file /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/2] c++ -MMD -MF /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o.d -pthread -B /home/user/anaconda3/envs/hs/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/user/anaconda3/envs/hs/include/python3.7m -c -c /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/fairseq/clib/libbleu/module.cpp -o /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  [2/2] c++ -MMD -MF /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o.d -pthread -B /home/user/anaconda3/envs/hs/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/user/anaconda3/envs/hs/include/python3.7m -c -c /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/fairseq/clib/libbleu/libbleu.cpp -o /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  g++ -pthread -shared -B /home/user/anaconda3/envs/hs/compiler_compat -L/home/user/anaconda3/envs/hs/lib -Wl,-rpath=/home/user/anaconda3/envs/hs/lib -Wl,--no-as-needed -Wl,--sysroot=/ /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o /tmp/pip-install-ojhp_3oh/fairseq_1676af6a5a1d41f7960da485ac27c326/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so\n",
      "  building 'fairseq.data.data_utils_fast' extension\n",
      "  error: unknown file type '.pyx' (from 'fairseq/data/data_utils_fast.pyx')\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for fairseq\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for fairseq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build fairseq\n",
      "Installing collected packages: portalocker, sacrebleu, cython, fairseq\n",
      "    Running setup.py install for fairseq ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: fairseq was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
      "\u001b[?25hSuccessfully installed cython-0.29.23 fairseq-0.9.0 portalocker-2.0.0 sacrebleu-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fairseq==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c5340a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.0\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "\n",
    "print(fairseq.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c225563d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.9.0\n",
      "  Using cached transformers-2.9.0-py3-none-any.whl (635 kB)\n",
      "Requirement already satisfied: numpy in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from transformers==2.9.0) (1.20.1)\n",
      "Requirement already satisfied: sentencepiece in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from transformers==2.9.0) (0.1.95)\n",
      "Requirement already satisfied: sacremoses in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from transformers==2.9.0) (0.0.45)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from transformers==2.9.0) (4.42.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from transformers==2.9.0) (2020.11.13)\n",
      "Requirement already satisfied: requests in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from transformers==2.9.0) (2.25.1)\n",
      "Collecting tokenizers==0.7.0\n",
      "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 676 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from transformers==2.9.0) (3.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from requests->transformers==2.9.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from requests->transformers==2.9.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from requests->transformers==2.9.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from requests->transformers==2.9.0) (4.0.0)\n",
      "Requirement already satisfied: click in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from sacremoses->transformers==2.9.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from sacremoses->transformers==2.9.0) (1.0.0)\n",
      "Requirement already satisfied: six in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from sacremoses->transformers==2.9.0) (1.15.0)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.5.2\n",
      "    Uninstalling tokenizers-0.5.2:\n",
      "      Successfully uninstalled tokenizers-0.5.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.5.1\n",
      "    Uninstalling transformers-2.5.1:\n",
      "      Successfully uninstalled transformers-2.5.1\n",
      "Successfully installed tokenizers-0.7.0 transformers-2.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b1841e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97bad9",
   "metadata": {},
   "source": [
    "### ㅁ만약 import transformers에서 python3 관련 에러가 발생할 경우 다음을 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ea8231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'apex'에 복제합니다...\n",
      "warning: https://github.com/nvidia/apex.git/(으)로 리다이렉트\n",
      "remote: Enumerating objects: 8042, done.\u001b[K\n",
      "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
      "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
      "remote: Total 8042 (delta 61), reused 69 (delta 30), pack-reused 7913\u001b[K\n",
      "오브젝트를 받는 중: 100% (8042/8042), 14.11 MiB | 6.41 MiB/s, 완료.\n",
      "델타를 알아내는 중: 100% (5460/5460), 완료.\n",
      "python: can't open file 'setup.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!git clone https://www.github.com/nvidia/apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7157d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa704996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode/apex\n"
     ]
    }
   ],
   "source": [
    "%cd apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d286b7d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp-7c85b1e2.so.1 library.\r\n",
      "\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\r\n"
     ]
    }
   ],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0de5c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode/apex\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f313a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a14f89",
   "metadata": {},
   "source": [
    "## /src/scripts/bert_trec_lower.sh\n",
    "- 경로 다 바꾸고 다음 코드 실행할것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_trec_lower.sh 파일 상단에 경로 다음과 같이 알맞게 바꾸고\n",
    "'''\n",
    "SRC=/home/user/Tae_StudyCode/TransformersDataAugmentation/src\n",
    "CACHE=/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE\n",
    "TASK=trec\n",
    "\n",
    "for NUMEXAMPLES in 10;\n",
    "do\n",
    "    for i in {0..14};\n",
    "        do\n",
    "        RAWDATADIR=/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/${TASK}/exp_${i}_${NUMEXAMPLES}\n",
    "\n",
    "       # Baseline classifier\n",
    "        python $SRC/bert_aug/bert_classifier.py --task $TASK  --data_dir $RAWDATADIR --seed ${i} --learning_rate $BERTLR --cache $CACHE > $RAWDATADIR/bert_baseline.log\n",
    "\n",
    "'''\n",
    "# 필요한 분류기만 학습해서 augmentation하면 될 거 같은데\n",
    "# cbert말고 그냥버트가 뭐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e82b2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3ec3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Tae_StudyCode/TransformersDataAugmentation/src/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd TransformersDataAugmentation/src/scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366d3004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=0, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 14:35:49 - INFO - filelock -   Lock 140079765170064 acquired on /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
      "05/23/2021 14:35:49 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json not found in cache or force_download set to True, downloading to /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/tmp6kmhkwol\n",
      "Downloading: 100%|█████████████████████████| 1.04M/1.04M [00:01<00:00, 1.01MB/s]\n",
      "05/23/2021 14:35:51 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json in cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 14:35:51 - INFO - transformers.file_utils -   creating metadata file for /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 14:35:51 - INFO - filelock -   Lock 140079765170064 released on /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
      "05/23/2021 14:35:51 - INFO - filelock -   Lock 140079765170064 acquired on /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "05/23/2021 14:35:51 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt not found in cache or force_download set to True, downloading to /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/tmpjs5i8w7s\n",
      "Downloading: 100%|████████████████████████████| 456k/456k [00:00<00:00, 466kB/s]\n",
      "05/23/2021 14:35:53 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt in cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 14:35:53 - INFO - transformers.file_utils -   creating metadata file for /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 14:35:53 - INFO - filelock -   Lock 140079765170064 released on /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "05/23/2021 14:35:53 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 14:35:53 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 14:35:54 - INFO - filelock -   Lock 140079736958544 acquired on /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e.lock\n",
      "05/23/2021 14:35:54 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json not found in cache or force_download set to True, downloading to /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/tmpxdjv4hmg\n",
      "Downloading: 100%|██████████████████████████████| 665/665 [00:00<00:00, 693kB/s]\n",
      "05/23/2021 14:35:55 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json in cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 14:35:55 - INFO - transformers.file_utils -   creating metadata file for /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 14:35:55 - INFO - filelock -   Lock 140079736958544 released on /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e.lock\n",
      "05/23/2021 14:35:55 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 14:35:55 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23/2021 14:35:56 - INFO - filelock -   Lock 140079736955664 acquired on /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1.lock\n",
      "05/23/2021 14:35:56 - INFO - transformers.file_utils -   https://cdn.huggingface.co/gpt2-pytorch_model.bin not found in cache or force_download set to True, downloading to /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/tmp010f4mu_\n",
      "Downloading: 100%|███████████████████████████| 548M/548M [01:07<00:00, 8.13MB/s]\n",
      "05/23/2021 14:37:05 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/gpt2-pytorch_model.bin in cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 14:37:05 - INFO - transformers.file_utils -   creating metadata file for /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 14:37:05 - INFO - filelock -   Lock 140079736955664 released on /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1.lock\n",
      "05/23/2021 14:37:05 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 14:37:08 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 14:37:08 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 14:37:08 - INFO - __main__ -     Num examples = 17\n",
      "05/23/2021 14:37:08 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 14:37:08 - INFO - __main__ -     Num steps = 13\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.836859703063965\n",
      "Saving model. Best dev so far 4.836859703063965\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:20,  3.36s/it]Epoch 1, Dev loss 4.5473713874816895\n",
      "Saving model. Best dev so far 4.5473713874816895\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:06<01:18,  3.42s/it]Epoch 2, Dev loss 4.293460369110107\n",
      "Saving model. Best dev so far 4.293460369110107\n",
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:16,  3.48s/it]Epoch 3, Dev loss 4.049797058105469\n",
      "Saving model. Best dev so far 4.049797058105469\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:13<01:12,  3.47s/it]Epoch 4, Dev loss 3.8105409145355225\n",
      "Saving model. Best dev so far 3.8105409145355225\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:09,  3.45s/it]Epoch 5, Dev loss 3.6026415824890137\n",
      "Saving model. Best dev so far 3.6026415824890137\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:20<01:06,  3.49s/it]Epoch 6, Dev loss 3.4194047451019287\n",
      "Saving model. Best dev so far 3.4194047451019287\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:03,  3.52s/it]Epoch 7, Dev loss 3.277712106704712\n",
      "Saving model. Best dev so far 3.277712106704712\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:27<00:59,  3.49s/it]Epoch 8, Dev loss 3.1894655227661133\n",
      "Saving model. Best dev so far 3.1894655227661133\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:31<00:55,  3.49s/it]Epoch 9, Dev loss 3.132988929748535\n",
      "Saving model. Best dev so far 3.132988929748535\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:52,  3.47s/it]Epoch 10, Dev loss 3.0958123207092285\n",
      "Saving model. Best dev so far 3.0958123207092285\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:38<00:48,  3.46s/it]Epoch 11, Dev loss 3.069059133529663\n",
      "Saving model. Best dev so far 3.069059133529663\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:41<00:45,  3.50s/it]Epoch 12, Dev loss 3.0482285022735596\n",
      "Saving model. Best dev so far 3.0482285022735596\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:45<00:41,  3.48s/it]Epoch 13, Dev loss 3.0306851863861084\n",
      "Saving model. Best dev so far 3.0306851863861084\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:48<00:38,  3.47s/it]Epoch 14, Dev loss 3.015671730041504\n",
      "Saving model. Best dev so far 3.015671730041504\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:52<00:34,  3.46s/it]Epoch 15, Dev loss 3.0023744106292725\n",
      "Saving model. Best dev so far 3.0023744106292725\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:55<00:31,  3.45s/it]Epoch 16, Dev loss 2.990713596343994\n",
      "Saving model. Best dev so far 2.990713596343994\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:59<00:27,  3.47s/it]Epoch 17, Dev loss 2.9811370372772217\n",
      "Saving model. Best dev so far 2.9811370372772217\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:02<00:24,  3.46s/it]Epoch 18, Dev loss 2.972576856613159\n",
      "Saving model. Best dev so far 2.972576856613159\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:05<00:20,  3.46s/it]Epoch 19, Dev loss 2.967575788497925\n",
      "Saving model. Best dev so far 2.967575788497925\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:09<00:17,  3.45s/it]Epoch 20, Dev loss 2.964284658432007\n",
      "Saving model. Best dev so far 2.964284658432007\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:12<00:13,  3.45s/it]Epoch 21, Dev loss 2.9642295837402344\n",
      "Saving model. Best dev so far 2.9642295837402344\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:16<00:10,  3.44s/it]Epoch 22, Dev loss 2.967099189758301\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:19<00:06,  3.32s/it]Epoch 23, Dev loss 2.974004030227661\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:22<00:03,  3.25s/it]Epoch 24, Dev loss 2.9832425117492676\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:25<00:00,  3.41s/it]\n",
      "Downloading: 100%|████████████████████████████| 232k/232k [00:00<00:00, 373kB/s]\n",
      "Downloading: 100%|██████████████████████████████| 433/433 [00:00<00:00, 496kB/s]\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:54<00:00, 8.07MB/s]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.29s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.16it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.73it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.68it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.81it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.01it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.45it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.84it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/bt', sample_num=1, seed=0, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.55it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.94it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.75it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.53it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.91it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.90it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.64it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.61it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.82it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.61it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.94it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.38it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 14:47:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 14:47:40 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 14:47:40 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 14:47:40 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 14:47:43 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 14:47:43 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   tokens: [CLS] what is columbia tri ##star ' s phone number ? [SEP]\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   init_ids: 101 2054 2003 3996 13012 14117 1005 1055 3042 2193 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   input_ids: 101 2054 2003 3996 13012 14117 1005 1055 103 2193 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 3042 2193 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   tokens: [CLS] how big is our galaxy in diameter ? [SEP]\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   init_ids: 101 2129 2502 2003 2256 9088 1999 6705 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   input_ids: 101 2129 2502 2003 2256 103 103 6705 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 9088 1999 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   tokens: [CLS] how do you select wine ? [SEP]\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   init_ids: 101 2129 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   input_ids: 101 2129 2079 2017 7276 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 4511 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   tokens: [CLS] what do you know about multicultural and multi ##ling ##ual schools ? [SEP]\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   init_ids: 101 2054 2079 2017 2113 2055 27135 1998 4800 2989 8787 2816 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   input_ids: 101 2054 2079 2017 2113 2055 27135 1998 4800 2989 103 2816 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 8787 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 14:47:43 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 14:47:43 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 14:47:43 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 14:47:43 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:58<00:00, 11.88s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.19it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.03it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.98it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.74it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.79it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.27it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.81it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.90it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.09it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.04it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 14:54:24 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 14:54:25 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 14:54:25 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 14:54:25 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 14:54:27 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 14:54:27 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 14:54:27 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   tokens: [CLS] numeric what is columbia tri ##star ' s phone number ? [SEP]\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   init_ids: 101 30522 2054 2003 3996 13012 14117 1005 1055 3042 2193 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   input_ids: 101 30522 2054 2003 3996 13012 14117 1005 1055 103 2193 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 3042 2193 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   tokens: [CLS] numeric how big is our galaxy in diameter ? [SEP]\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   init_ids: 101 30522 2129 2502 2003 2256 9088 1999 6705 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   input_ids: 101 30522 2129 2502 2003 2256 103 103 6705 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 9088 1999 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   tokens: [CLS] description how do you select wine ? [SEP]\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   init_ids: 101 6412 2129 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   input_ids: 101 6412 2129 2079 2017 7276 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 4511 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   tokens: [CLS] description what do you know about multicultural and multi ##ling ##ual schools ? [SEP]\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   init_ids: 101 6412 2054 2079 2017 2113 2055 27135 1998 4800 2989 8787 2816 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   input_ids: 101 6412 2054 2079 2017 2113 2055 27135 1998 4800 2989 103 2816 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 8787 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 14:54:28 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 14:54:28 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 14:54:28 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 14:54:28 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:39<00:00, 11.87s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.84it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.82it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.12it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.47it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.77it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.60it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.25it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.85it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.22it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.77it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_0_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 15:28:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 15:28:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 15:28:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 15:28:29 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 15:28:32 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 15:28:32 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   tokens: [CLS] nu ##meric what is columbia tri ##star ' s phone number ? [SEP]\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2003 3996 13012 14117 1005 1055 3042 2193 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   input_ids: 101 16371 25531 2054 2003 3996 13012 14117 1005 1055 103 2193 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 3042 2193 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   tokens: [CLS] nu ##meric how big is our galaxy in diameter ? [SEP]\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   init_ids: 101 16371 25531 2129 2502 2003 2256 9088 1999 6705 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   input_ids: 101 16371 25531 2129 2502 2003 2256 103 103 6705 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 9088 1999 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   tokens: [CLS] description how do you select wine ? [SEP]\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   init_ids: 101 6412 2129 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   input_ids: 101 6412 2129 2079 2017 7276 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 4511 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   tokens: [CLS] description what do you know about multicultural and multi ##ling ##ual schools ? [SEP]\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   init_ids: 101 6412 2054 2079 2017 2113 2055 27135 1998 4800 2989 8787 2816 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   input_ids: 101 6412 2054 2079 2017 2113 2055 27135 1998 4800 2989 103 2816 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 8787 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:28:32 - INFO - __main__ -   label_len: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23/2021 15:28:32 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 15:28:32 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 15:28:32 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 15:28:32 - INFO - __main__ -     Num steps = 75\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:59<00:00, 11.96s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.27s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.69it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.76it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.95it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.13it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.67it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.38it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.11it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.97it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.31it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.76it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.33it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.67it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.33it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=1, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 15:34:59 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 15:34:59 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 15:35:00 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 15:35:00 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 15:35:00 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 15:35:03 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 15:35:03 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 15:35:03 - INFO - __main__ -     Num examples = 17\n",
      "05/23/2021 15:35:03 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 15:35:03 - INFO - __main__ -     Num steps = 13\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.94047212600708\n",
      "Saving model. Best dev so far 4.94047212600708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:22,  3.43s/it]Epoch 1, Dev loss 4.66220760345459\n",
      "Saving model. Best dev so far 4.66220760345459\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:06<01:19,  3.44s/it]Epoch 2, Dev loss 4.416219711303711\n",
      "Saving model. Best dev so far 4.416219711303711\n",
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:17,  3.50s/it]Epoch 3, Dev loss 4.174371242523193\n",
      "Saving model. Best dev so far 4.174371242523193\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:13<01:13,  3.50s/it]Epoch 4, Dev loss 3.940532684326172\n",
      "Saving model. Best dev so far 3.940532684326172\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:09,  3.46s/it]Epoch 5, Dev loss 3.7381484508514404\n",
      "Saving model. Best dev so far 3.7381484508514404\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:20<01:05,  3.44s/it]Epoch 6, Dev loss 3.5636508464813232\n",
      "Saving model. Best dev so far 3.5636508464813232\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:01,  3.43s/it]Epoch 7, Dev loss 3.445563554763794\n",
      "Saving model. Best dev so far 3.445563554763794\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:27<00:58,  3.43s/it]Epoch 8, Dev loss 3.372792959213257\n",
      "Saving model. Best dev so far 3.372792959213257\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:30<00:54,  3.41s/it]Epoch 9, Dev loss 3.3260908126831055\n",
      "Saving model. Best dev so far 3.3260908126831055\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:51,  3.41s/it]Epoch 10, Dev loss 3.293142795562744\n",
      "Saving model. Best dev so far 3.293142795562744\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:37<00:47,  3.40s/it]Epoch 11, Dev loss 3.2676689624786377\n",
      "Saving model. Best dev so far 3.2676689624786377\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:41<00:44,  3.40s/it]Epoch 12, Dev loss 3.2453880310058594\n",
      "Saving model. Best dev so far 3.2453880310058594\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:44<00:40,  3.39s/it]Epoch 13, Dev loss 3.224827766418457\n",
      "Saving model. Best dev so far 3.224827766418457\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:47<00:37,  3.39s/it]Epoch 14, Dev loss 3.2050676345825195\n",
      "Saving model. Best dev so far 3.2050676345825195\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:51<00:33,  3.39s/it]Epoch 15, Dev loss 3.185945749282837\n",
      "Saving model. Best dev so far 3.185945749282837\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:54<00:30,  3.39s/it]Epoch 16, Dev loss 3.1682989597320557\n",
      "Saving model. Best dev so far 3.1682989597320557\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:58<00:27,  3.38s/it]Epoch 17, Dev loss 3.1522369384765625\n",
      "Saving model. Best dev so far 3.1522369384765625\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:01<00:23,  3.39s/it]Epoch 18, Dev loss 3.1390645503997803\n",
      "Saving model. Best dev so far 3.1390645503997803\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:04<00:20,  3.39s/it]Epoch 19, Dev loss 3.1301395893096924\n",
      "Saving model. Best dev so far 3.1301395893096924\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:08<00:17,  3.43s/it]Epoch 20, Dev loss 3.124560832977295\n",
      "Saving model. Best dev so far 3.124560832977295\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:11<00:13,  3.42s/it]Epoch 21, Dev loss 3.1216416358947754\n",
      "Saving model. Best dev so far 3.1216416358947754\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:15<00:10,  3.44s/it]Epoch 22, Dev loss 3.1215662956237793\n",
      "Saving model. Best dev so far 3.1215662956237793\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:18<00:06,  3.45s/it]Epoch 23, Dev loss 3.1256942749023438\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:21<00:03,  3.30s/it]Epoch 24, Dev loss 3.1323039531707764\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:24<00:00,  3.39s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.02it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.64it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.87it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.73it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.87it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.84it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.09it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.33it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.90it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.13it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/bt', sample_num=1, seed=1, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.26s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.83it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.99it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.21it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.43it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.79it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.11it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.80it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.05it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.16it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.07it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.78it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.13it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 15:44:47 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 15:44:48 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 15:44:48 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 15:44:48 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 15:44:51 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 15:44:51 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   tokens: [CLS] what debts did qin ##te ##x group leave ? [SEP]\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   init_ids: 101 2054 13930 2106 19781 2618 2595 2177 2681 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   input_ids: 101 2054 13930 2106 19781 2618 103 103 2681 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 2595 2177 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   tokens: [CLS] in what year was the cannon invented ? [SEP]\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   init_ids: 101 1999 2054 2095 2001 1996 8854 8826 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   input_ids: 101 1999 2054 2095 2001 103 8854 8826 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 -100 -100 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   tokens: [CLS] what are some children ' s rights ? [SEP]\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   init_ids: 101 2054 2024 2070 2336 1005 1055 2916 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   input_ids: 101 2054 2024 2070 103 1005 1055 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2336 -100 -100 2916 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   tokens: [CLS] what is the highest roman nu ##meral ? [SEP]\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   init_ids: 101 2054 2003 1996 3284 3142 16371 28990 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   input_ids: 101 2054 2003 103 3284 103 16371 28990 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 1996 -100 3142 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:44:51 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 15:44:51 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 15:44:51 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 15:44:51 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:03<00:00, 12.32s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.65it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.13it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.81it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.91it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.53it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.73it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.00it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.22it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 15:51:22 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 15:51:23 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 15:51:23 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 15:51:23 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 15:51:25 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 15:51:25 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 15:51:25 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   tokens: [CLS] numeric what debts did qin ##te ##x group leave ? [SEP]\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   init_ids: 101 30522 2054 13930 2106 19781 2618 2595 2177 2681 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   input_ids: 101 30522 2054 13930 2106 19781 2618 103 103 2681 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 2595 2177 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   tokens: [CLS] numeric in what year was the cannon invented ? [SEP]\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   init_ids: 101 30522 1999 2054 2095 2001 1996 8854 8826 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   input_ids: 101 30522 1999 2054 2095 2001 103 8854 8826 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2054 -100 -100 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   tokens: [CLS] description what are some children ' s rights ? [SEP]\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   init_ids: 101 6412 2054 2024 2070 2336 1005 1055 2916 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   input_ids: 101 6412 2054 2024 2070 103 1005 1055 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 2336 -100 -100 2916 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   tokens: [CLS] description what is the highest roman nu ##meral ? [SEP]\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   init_ids: 101 6412 2054 2003 1996 3284 3142 16371 28990 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   input_ids: 101 6412 2054 2003 103 3284 103 16371 28990 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1996 -100 3142 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 15:51:26 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 15:51:26 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 15:51:26 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 15:51:26 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:45<00:00, 11.90s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.29s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.55it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.50it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.84it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.94it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.96it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.99it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.12it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.03it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.09it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.18it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.81it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.58it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_1_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 16:25:58 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 16:25:59 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 16:25:59 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 16:25:59 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 16:26:01 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 16:26:01 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   tokens: [CLS] nu ##meric what debts did qin ##te ##x group leave ? [SEP]\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   init_ids: 101 16371 25531 2054 13930 2106 19781 2618 2595 2177 2681 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   input_ids: 101 16371 25531 2054 13930 2106 19781 2618 103 103 2681 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 2595 2177 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   tokens: [CLS] nu ##meric in what year was the cannon invented ? [SEP]\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   init_ids: 101 16371 25531 1999 2054 2095 2001 1996 8854 8826 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   input_ids: 101 16371 25531 1999 2054 2095 2001 103 8854 8826 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2054 -100 -100 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   tokens: [CLS] description what are some children ' s rights ? [SEP]\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   init_ids: 101 6412 2054 2024 2070 2336 1005 1055 2916 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   input_ids: 101 6412 2054 2024 2070 103 1005 1055 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 2336 -100 -100 2916 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   tokens: [CLS] description what is the highest roman nu ##meral ? [SEP]\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   init_ids: 101 6412 2054 2003 1996 3284 3142 16371 28990 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   input_ids: 101 6412 2054 2003 103 3284 103 16371 28990 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1996 -100 3142 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 16:26:01 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 16:26:01 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 16:26:01 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 16:26:01 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:01<00:00, 12.14s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.95it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.78it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.92it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.64it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.16it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.30it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.57it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.46it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=2, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 16:32:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 16:32:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 16:32:16 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 16:32:16 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 16:32:16 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 16:32:19 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 16:32:19 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 16:32:19 - INFO - __main__ -     Num examples = 16\n",
      "05/23/2021 16:32:19 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 16:32:19 - INFO - __main__ -     Num steps = 12\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.9718756675720215\n",
      "Saving model. Best dev so far 4.9718756675720215\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:22,  3.43s/it]Epoch 1, Dev loss 4.68474817276001\n",
      "Saving model. Best dev so far 4.68474817276001\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:06<01:17,  3.39s/it]Epoch 2, Dev loss 4.434874534606934\n",
      "Saving model. Best dev so far 4.434874534606934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:14,  3.37s/it]Epoch 3, Dev loss 4.1932268142700195\n",
      "Saving model. Best dev so far 4.1932268142700195\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:13<01:10,  3.34s/it]Epoch 4, Dev loss 3.950866460800171\n",
      "Saving model. Best dev so far 3.950866460800171\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:16<01:06,  3.33s/it]Epoch 5, Dev loss 3.7330079078674316\n",
      "Saving model. Best dev so far 3.7330079078674316\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:20<01:03,  3.35s/it]Epoch 6, Dev loss 3.5420279502868652\n",
      "Saving model. Best dev so far 3.5420279502868652\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:23<00:59,  3.33s/it]Epoch 7, Dev loss 3.395021915435791\n",
      "Saving model. Best dev so far 3.395021915435791\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:26<00:56,  3.33s/it]Epoch 8, Dev loss 3.2995920181274414\n",
      "Saving model. Best dev so far 3.2995920181274414\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:30<00:53,  3.32s/it]Epoch 9, Dev loss 3.237499952316284\n",
      "Saving model. Best dev so far 3.237499952316284\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:33<00:50,  3.33s/it]Epoch 10, Dev loss 3.196288824081421\n",
      "Saving model. Best dev so far 3.196288824081421\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:36<00:46,  3.33s/it]Epoch 11, Dev loss 3.166151285171509\n",
      "Saving model. Best dev so far 3.166151285171509\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:40<00:43,  3.32s/it]Epoch 12, Dev loss 3.1413092613220215\n",
      "Saving model. Best dev so far 3.1413092613220215\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:43<00:40,  3.34s/it]Epoch 13, Dev loss 3.120394706726074\n",
      "Saving model. Best dev so far 3.120394706726074\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:46<00:36,  3.32s/it]Epoch 14, Dev loss 3.101668119430542\n",
      "Saving model. Best dev so far 3.101668119430542\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:50<00:33,  3.32s/it]Epoch 15, Dev loss 3.0841329097747803\n",
      "Saving model. Best dev so far 3.0841329097747803\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:53<00:29,  3.32s/it]Epoch 16, Dev loss 3.068237543106079\n",
      "Saving model. Best dev so far 3.068237543106079\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:56<00:26,  3.31s/it]Epoch 17, Dev loss 3.0546114444732666\n",
      "Saving model. Best dev so far 3.0546114444732666\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [00:59<00:23,  3.31s/it]Epoch 18, Dev loss 3.042677164077759\n",
      "Saving model. Best dev so far 3.042677164077759\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:03<00:19,  3.30s/it]Epoch 19, Dev loss 3.035248041152954\n",
      "Saving model. Best dev so far 3.035248041152954\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:06<00:16,  3.30s/it]Epoch 20, Dev loss 3.032827138900757\n",
      "Saving model. Best dev so far 3.032827138900757\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:09<00:13,  3.30s/it]Epoch 21, Dev loss 3.0333099365234375\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:12<00:09,  3.20s/it]Epoch 22, Dev loss 3.0370771884918213\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:15<00:06,  3.11s/it]Epoch 23, Dev loss 3.045356273651123\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:18<00:03,  3.03s/it]Epoch 24, Dev loss 3.0573854446411133\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:21<00:00,  3.26s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.65it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.07it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.74it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.11it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.28it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.15it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.24it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.75it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.82it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/bt', sample_num=1, seed=2, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.91it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.77it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.04it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.74it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.82it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.09it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.96it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.16it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.71it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.06it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.65it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 16:41:38 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 16:41:38 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 16:41:38 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 16:41:39 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 16:41:41 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 16:41:41 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   tokens: [CLS] in what year did thatcher gain power ? [SEP]\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   init_ids: 101 1999 2054 2095 2106 21127 5114 2373 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   input_ids: 101 1999 2054 2095 103 21127 103 2373 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2106 -100 5114 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   tokens: [CLS] what is the fine for having a dog on a beach ? [SEP]\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   init_ids: 101 2054 2003 1996 2986 2005 2383 1037 3899 2006 1037 3509 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   input_ids: 101 2054 2383 1996 2986 2005 2383 1037 3899 2006 1037 3509 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   masked_lm_labels: -100 -100 2003 -100 -100 -100 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   tokens: [CLS] why were red m & ms discontinued then brought back ? [SEP]\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   init_ids: 101 2339 2020 2417 1049 1004 5796 8944 2059 2716 2067 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   input_ids: 101 2339 2020 2417 1049 1004 5796 8944 103 2716 2067 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 2059 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   tokens: [CLS] how do you select wine ? [SEP]\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   init_ids: 101 2129 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   input_ids: 101 103 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:41:41 - INFO - __main__ -   masked_lm_labels: -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23/2021 16:41:41 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 16:41:41 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 16:41:41 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 16:41:41 - INFO - __main__ -     Num steps = 75\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:00<00:00, 12.07s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.82it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.00it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.05it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.60it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.06it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.98it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.83it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.81it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.86it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.74it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.58it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 16:48:26 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 16:48:27 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 16:48:27 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 16:48:27 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 16:48:30 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 16:48:30 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 16:48:30 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   tokens: [CLS] numeric in what year did thatcher gain power ? [SEP]\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   init_ids: 101 30522 1999 2054 2095 2106 21127 5114 2373 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   input_ids: 101 30522 1999 2054 2095 103 21127 103 2373 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 2106 -100 5114 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   tokens: [CLS] numeric what is the fine for having a dog on a beach ? [SEP]\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   init_ids: 101 30522 2054 2003 1996 2986 2005 2383 1037 3899 2006 1037 3509 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   input_ids: 101 30522 2054 2383 1996 2986 2005 2383 1037 3899 2006 1037 3509 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2003 -100 -100 -100 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   tokens: [CLS] description why were red m & ms discontinued then brought back ? [SEP]\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   init_ids: 101 6412 2339 2020 2417 1049 1004 5796 8944 2059 2716 2067 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   input_ids: 101 6412 2339 2020 2417 1049 1004 5796 8944 103 2716 2067 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 2059 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   tokens: [CLS] description how do you select wine ? [SEP]\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   init_ids: 101 6412 2129 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   input_ids: 101 6412 103 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   masked_lm_labels: -100 -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 16:48:30 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 16:48:30 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 16:48:30 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 16:48:30 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:54<00:00, 11.97s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.10it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.74it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.91it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.81it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.97it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.44it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.70it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.67it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.78it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.99it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.16it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_2_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 17:22:53 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 17:22:54 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 17:22:54 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 17:22:54 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 17:22:56 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 17:22:56 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   tokens: [CLS] nu ##meric in what year did thatcher gain power ? [SEP]\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   init_ids: 101 16371 25531 1999 2054 2095 2106 21127 5114 2373 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   input_ids: 101 16371 25531 1999 2054 2095 103 21127 103 2373 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 2106 -100 5114 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   tokens: [CLS] nu ##meric what is the fine for having a dog on a beach ? [SEP]\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2003 1996 2986 2005 2383 1037 3899 2006 1037 3509 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   input_ids: 101 16371 25531 2054 2383 1996 2986 2005 2383 1037 3899 2006 1037 3509 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2003 -100 -100 -100 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   tokens: [CLS] description why were red m & ms discontinued then brought back ? [SEP]\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   init_ids: 101 6412 2339 2020 2417 1049 1004 5796 8944 2059 2716 2067 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   input_ids: 101 6412 2339 2020 2417 1049 1004 5796 8944 103 2716 2067 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 2059 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   tokens: [CLS] description how do you select wine ? [SEP]\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   init_ids: 101 6412 2129 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   input_ids: 101 6412 103 2079 2017 7276 4511 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   masked_lm_labels: -100 -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 17:22:56 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 17:22:56 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 17:22:56 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 17:22:56 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:58<00:00, 11.89s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.27s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.62it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.93it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.84it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.84it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.29it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.63it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.91it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=3, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 17:29:06 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 17:29:06 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 17:29:07 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 17:29:07 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 17:29:07 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 17:29:10 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 17:29:10 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 17:29:10 - INFO - __main__ -     Num examples = 17\n",
      "05/23/2021 17:29:10 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 17:29:10 - INFO - __main__ -     Num steps = 13\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.752464771270752\n",
      "Saving model. Best dev so far 4.752464771270752\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:24,  3.52s/it]Epoch 1, Dev loss 4.465269088745117\n",
      "Saving model. Best dev so far 4.465269088745117\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:06<01:20,  3.49s/it]Epoch 2, Dev loss 4.213643550872803\n",
      "Saving model. Best dev so far 4.213643550872803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:16,  3.46s/it]Epoch 3, Dev loss 3.9655044078826904\n",
      "Saving model. Best dev so far 3.9655044078826904\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:13<01:12,  3.44s/it]Epoch 4, Dev loss 3.714172840118408\n",
      "Saving model. Best dev so far 3.714172840118408\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:08,  3.45s/it]Epoch 5, Dev loss 3.4895946979522705\n",
      "Saving model. Best dev so far 3.4895946979522705\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:20<01:05,  3.44s/it]Epoch 6, Dev loss 3.301360845565796\n",
      "Saving model. Best dev so far 3.301360845565796\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:01,  3.44s/it]Epoch 7, Dev loss 3.1699559688568115\n",
      "Saving model. Best dev so far 3.1699559688568115\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:27<00:58,  3.47s/it]Epoch 8, Dev loss 3.090825319290161\n",
      "Saving model. Best dev so far 3.090825319290161\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:31<00:55,  3.46s/it]Epoch 9, Dev loss 3.040313482284546\n",
      "Saving model. Best dev so far 3.040313482284546\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:51,  3.44s/it]Epoch 10, Dev loss 3.0047106742858887\n",
      "Saving model. Best dev so far 3.0047106742858887\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:37<00:47,  3.43s/it]Epoch 11, Dev loss 2.9765353202819824\n",
      "Saving model. Best dev so far 2.9765353202819824\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:41<00:44,  3.45s/it]Epoch 12, Dev loss 2.953579902648926\n",
      "Saving model. Best dev so far 2.953579902648926\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:44<00:41,  3.44s/it]Epoch 13, Dev loss 2.9345202445983887\n",
      "Saving model. Best dev so far 2.9345202445983887\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:48<00:37,  3.42s/it]Epoch 14, Dev loss 2.9179110527038574\n",
      "Saving model. Best dev so far 2.9179110527038574\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:52<00:35,  3.53s/it]Epoch 15, Dev loss 2.90400767326355\n",
      "Saving model. Best dev so far 2.90400767326355\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:55<00:31,  3.54s/it]Epoch 16, Dev loss 2.8931477069854736\n",
      "Saving model. Best dev so far 2.8931477069854736\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:58<00:27,  3.49s/it]Epoch 17, Dev loss 2.8844666481018066\n",
      "Saving model. Best dev so far 2.8844666481018066\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:02<00:24,  3.47s/it]Epoch 18, Dev loss 2.8780829906463623\n",
      "Saving model. Best dev so far 2.8780829906463623\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:05<00:20,  3.45s/it]Epoch 19, Dev loss 2.875427484512329\n",
      "Saving model. Best dev so far 2.875427484512329\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:09<00:17,  3.44s/it]Epoch 20, Dev loss 2.87648868560791\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:12<00:13,  3.33s/it]Epoch 21, Dev loss 2.880938768386841\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:15<00:09,  3.31s/it]Epoch 22, Dev loss 2.8890140056610107\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:18<00:06,  3.23s/it]Epoch 23, Dev loss 2.901416063308716\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:21<00:03,  3.16s/it]Epoch 24, Dev loss 2.915147066116333\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:24<00:00,  3.38s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.82it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.93it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.33it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.96it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.05it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/bt', sample_num=1, seed=3, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.91it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.02it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.90it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.80it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.49it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.07it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.49it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.19it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.63it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.92it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.03it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 17:38:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 17:38:30 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 17:38:30 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 17:38:30 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 17:38:33 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 17:38:33 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   tokens: [CLS] how old is the italian artist ma ##uri ##zio pe ##lle ##grin ? [SEP]\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   init_ids: 101 2129 2214 2003 1996 3059 3063 5003 9496 12426 21877 6216 24860 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   input_ids: 101 2129 2214 2003 1996 3059 3063 5003 9496 12426 21877 6216 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 24860 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   tokens: [CLS] when did luce ##lly garcia , a former ambassador of columbia to honduras , die ? [SEP]\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   init_ids: 101 2043 2106 19913 9215 7439 1010 1037 2280 6059 1997 3996 2000 14373 1010 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   input_ids: 101 2043 103 19913 9215 7439 1010 1037 2280 6059 1997 3996 103 14373 1010 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   masked_lm_labels: -100 -100 2106 -100 -100 -100 1010 -100 -100 -100 -100 -100 2000 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   tokens: [CLS] what ' s the meaning of the latin battle cry : ad arm ##a , ad arm ##a . [SEP]\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   init_ids: 101 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   input_ids: 101 2054 1005 1055 103 3574 1997 103 3763 103 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1996 -100 -100 1996 -100 2645 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   tokens: [CLS] what category does the color pink denote in the trivial pursuit baby boom ##er edition ? [SEP]\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   init_ids: 101 2054 4696 2515 1996 3609 5061 19090 1999 1996 20610 8463 3336 8797 2121 3179 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   input_ids: 101 2054 4696 2515 1996 3609 8463 19090 1999 1996 20610 8463 103 8797 2121 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 5061 -100 -100 -100 -100 -100 3336 -100 -100 3179 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:38:33 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 17:38:33 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 17:38:33 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 17:38:33 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:05<00:00, 12.57s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.30s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.48it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.13it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.03it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.48it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.93it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.04it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.47it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.27s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.61it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.83it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.35it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 17:44:59 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 17:45:00 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 17:45:00 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 17:45:00 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 17:45:02 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 17:45:02 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 17:45:02 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   tokens: [CLS] numeric how old is the italian artist ma ##uri ##zio pe ##lle ##grin ? [SEP]\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   init_ids: 101 30522 2129 2214 2003 1996 3059 3063 5003 9496 12426 21877 6216 24860 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   input_ids: 101 30522 2129 2214 2003 1996 3059 3063 5003 9496 12426 21877 6216 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 24860 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   tokens: [CLS] numeric when did luce ##lly garcia , a former ambassador of columbia to honduras , die ? [SEP]\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   init_ids: 101 30522 2043 2106 19913 9215 7439 1010 1037 2280 6059 1997 3996 2000 14373 1010 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   input_ids: 101 30522 2043 103 19913 9215 7439 1010 1037 2280 6059 1997 3996 103 14373 1010 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2106 -100 -100 -100 1010 -100 -100 -100 -100 -100 2000 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   tokens: [CLS] description what ' s the meaning of the latin battle cry : ad arm ##a , ad arm ##a . [SEP]\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   init_ids: 101 6412 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   input_ids: 101 6412 2054 1005 1055 103 3574 1997 103 3763 103 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 1996 -100 -100 1996 -100 2645 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   tokens: [CLS] description what category does the color pink denote in the trivial pursuit baby boom ##er edition ? [SEP]\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   init_ids: 101 6412 2054 4696 2515 1996 3609 5061 19090 1999 1996 20610 8463 3336 8797 2121 3179 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   input_ids: 101 6412 2054 4696 2515 1996 3609 8463 19090 1999 1996 20610 8463 103 8797 2121 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 5061 -100 -100 -100 -100 -100 3336 -100 -100 3179 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 17:45:03 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 17:45:03 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 17:45:03 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 17:45:03 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [30:14<00:00, 12.10s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.79it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.55it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.93it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.95it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.72it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.61it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.62it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.46it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.29it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.46it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_3_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 18:19:42 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 18:19:43 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 18:19:43 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 18:19:43 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 18:19:45 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 18:19:45 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   tokens: [CLS] nu ##meric how old is the italian artist ma ##uri ##zio pe ##lle ##grin ? [SEP]\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   init_ids: 101 16371 25531 2129 2214 2003 1996 3059 3063 5003 9496 12426 21877 6216 24860 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   input_ids: 101 16371 25531 2129 103 2003 1996 3059 3063 5003 9496 12426 21877 6216 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2214 -100 -100 -100 -100 -100 -100 -100 -100 -100 24860 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   tokens: [CLS] nu ##meric when did luce ##lly garcia , a former ambassador of columbia to honduras , die ? [SEP]\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   init_ids: 101 16371 25531 2043 2106 19913 9215 7439 1010 1037 2280 6059 1997 3996 2000 14373 1010 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   input_ids: 101 16371 25531 2043 2106 19913 9215 103 1010 1037 2280 6059 1997 3996 103 14373 1010 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 7439 -100 -100 -100 -100 1997 -100 2000 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   tokens: [CLS] description what ' s the meaning of the latin battle cry : ad arm ##a , ad arm ##a . [SEP]\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   init_ids: 101 6412 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   input_ids: 101 6412 2054 1005 1055 103 3574 1997 103 3763 103 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 1996 -100 -100 1996 -100 2645 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   tokens: [CLS] description what category does the color pink denote in the trivial pursuit baby boom ##er edition ? [SEP]\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   init_ids: 101 6412 2054 4696 2515 1996 3609 5061 19090 1999 1996 20610 8463 3336 8797 2121 3179 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   input_ids: 101 6412 2054 4696 2515 1996 3609 8463 19090 1999 1996 20610 8463 103 8797 2121 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 5061 -100 -100 -100 -100 -100 3336 -100 -100 3179 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 18:19:45 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 18:19:45 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 18:19:45 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 18:19:45 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:59<00:00, 11.96s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.64it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.93it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.76it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.02it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.86it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.79it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.90it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.42it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:19<00:00,  3.22it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.01it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.84it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.54it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=4, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 18:26:12 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 18:26:12 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 18:26:13 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 18:26:13 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 18:26:13 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 18:26:16 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 18:26:16 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 18:26:16 - INFO - __main__ -     Num examples = 16\n",
      "05/23/2021 18:26:16 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 18:26:16 - INFO - __main__ -     Num steps = 12\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.950209140777588\n",
      "Saving model. Best dev so far 4.950209140777588\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:21,  3.41s/it]Epoch 1, Dev loss 4.675342082977295\n",
      "Saving model. Best dev so far 4.675342082977295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|██▉                                  | 2/25 [00:06<01:18,  3.40s/it]Epoch 2, Dev loss 4.4317097663879395\n",
      "Saving model. Best dev so far 4.4317097663879395\n",
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:14,  3.39s/it]Epoch 3, Dev loss 4.193823337554932\n",
      "Saving model. Best dev so far 4.193823337554932\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:13<01:10,  3.37s/it]Epoch 4, Dev loss 3.9587433338165283\n",
      "Saving model. Best dev so far 3.9587433338165283\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:08,  3.42s/it]Epoch 5, Dev loss 3.749509334564209\n",
      "Saving model. Best dev so far 3.749509334564209\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:20<01:04,  3.41s/it]Epoch 6, Dev loss 3.5754001140594482\n",
      "Saving model. Best dev so far 3.5754001140594482\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:23<01:01,  3.42s/it]Epoch 7, Dev loss 3.455918312072754\n",
      "Saving model. Best dev so far 3.455918312072754\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:27<00:57,  3.40s/it]Epoch 8, Dev loss 3.376112699508667\n",
      "Saving model. Best dev so far 3.376112699508667\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:30<00:55,  3.45s/it]Epoch 9, Dev loss 3.321356773376465\n",
      "Saving model. Best dev so far 3.321356773376465\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:51,  3.42s/it]Epoch 10, Dev loss 3.280237913131714\n",
      "Saving model. Best dev so far 3.280237913131714\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:37<00:47,  3.40s/it]Epoch 11, Dev loss 3.2471094131469727\n",
      "Saving model. Best dev so far 3.2471094131469727\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:40<00:43,  3.38s/it]Epoch 12, Dev loss 3.2204575538635254\n",
      "Saving model. Best dev so far 3.2204575538635254\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:44<00:40,  3.37s/it]Epoch 13, Dev loss 3.199134349822998\n",
      "Saving model. Best dev so far 3.199134349822998\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:47<00:36,  3.36s/it]Epoch 14, Dev loss 3.182713508605957\n",
      "Saving model. Best dev so far 3.182713508605957\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:50<00:33,  3.35s/it]Epoch 15, Dev loss 3.169668197631836\n",
      "Saving model. Best dev so far 3.169668197631836\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:54<00:30,  3.35s/it]Epoch 16, Dev loss 3.159295082092285\n",
      "Saving model. Best dev so far 3.159295082092285\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:57<00:26,  3.35s/it]Epoch 17, Dev loss 3.151374101638794\n",
      "Saving model. Best dev so far 3.151374101638794\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:00<00:23,  3.34s/it]Epoch 18, Dev loss 3.145869016647339\n",
      "Saving model. Best dev so far 3.145869016647339\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:04<00:20,  3.34s/it]Epoch 19, Dev loss 3.142491340637207\n",
      "Saving model. Best dev so far 3.142491340637207\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:07<00:16,  3.33s/it]Epoch 20, Dev loss 3.1432480812072754\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:10<00:12,  3.21s/it]Epoch 21, Dev loss 3.1477489471435547\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:13<00:09,  3.13s/it]Epoch 22, Dev loss 3.1561288833618164\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:16<00:06,  3.06s/it]Epoch 23, Dev loss 3.1684062480926514\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:19<00:03,  3.01s/it]Epoch 24, Dev loss 3.1858389377593994\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:22<00:00,  3.29s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.28s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.52it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.59it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.97it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.90it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.73it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.87it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.91it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.93it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.96it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.20it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.00it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/bt', sample_num=1, seed=4, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.90it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.36it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.07s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.28it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.58it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.45it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.60it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.54it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.33it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 18:35:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 18:35:40 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 18:35:40 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 18:35:40 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 18:35:43 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 18:35:43 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   tokens: [CLS] what is the world population as of today ? [SEP]\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   init_ids: 101 2054 2003 1996 2088 2313 2004 1997 2651 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   input_ids: 101 2054 103 103 2088 2313 2004 1997 2651 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   masked_lm_labels: -100 -100 2003 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   tokens: [CLS] when is the thai new year ? [SEP]\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   init_ids: 101 2043 2003 1996 7273 2047 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   input_ids: 101 2043 2003 1996 7273 2047 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 7273 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   tokens: [CLS] what ' s the meaning of the latin battle cry : ad arm ##a , ad arm ##a . [SEP]\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   init_ids: 101 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   input_ids: 101 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 103 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 1997 -100 -100 -100 -100 -100 -100 -100 -100 1010 -100 2849 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   tokens: [CLS] what are faults in the earth ' s crust ? [SEP]\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   init_ids: 101 2054 2024 19399 1999 1996 3011 1005 1055 19116 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   input_ids: 101 2054 2024 19399 1999 1996 3011 103 103 19116 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1005 1055 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:35:43 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 18:35:43 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 18:35:43 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 18:35:43 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:03<00:00, 12.39s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.26s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.21it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.11it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.98it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.90it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.98it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.84it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.64it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.81it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.26it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.95it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 18:42:00 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 18:42:01 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 18:42:01 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 18:42:01 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 18:42:03 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 18:42:03 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 18:42:03 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   tokens: [CLS] numeric what is the world population as of today ? [SEP]\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   init_ids: 101 30522 2054 2003 1996 2088 2313 2004 1997 2651 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   input_ids: 101 30522 2054 103 103 2088 2313 2004 1997 2651 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2003 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   tokens: [CLS] numeric when is the thai new year ? [SEP]\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   init_ids: 101 30522 2043 2003 1996 7273 2047 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   input_ids: 101 30522 2043 2003 1996 7273 2047 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 7273 -100 2095 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   tokens: [CLS] description what ' s the meaning of the latin battle cry : ad arm ##a , ad arm ##a . [SEP]\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   init_ids: 101 6412 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   input_ids: 101 6412 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 103 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1997 -100 -100 -100 -100 -100 -100 -100 -100 1010 -100 2849 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   tokens: [CLS] description what are faults in the earth ' s crust ? [SEP]\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   init_ids: 101 6412 2054 2024 19399 1999 1996 3011 1005 1055 19116 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   input_ids: 101 6412 2054 2024 19399 1999 1996 3011 103 103 19116 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 1005 1055 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 18:42:04 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 18:42:04 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 18:42:04 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 18:42:04 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:51<00:00, 11.94s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.26s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.58it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.14it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.63it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.87it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.58it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.82it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.85it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.59it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.91it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.64it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.70it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.33it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_4_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 19:16:23 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 19:16:24 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 19:16:24 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 19:16:24 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 19:16:26 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 19:16:26 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   tokens: [CLS] nu ##meric what is the world population as of today ? [SEP]\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2003 1996 2088 2313 2004 1997 2651 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   input_ids: 101 16371 25531 2054 103 103 2088 2313 2004 1997 2651 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2003 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   tokens: [CLS] nu ##meric when is the thai new year ? [SEP]\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   init_ids: 101 16371 25531 2043 2003 1996 7273 2047 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   input_ids: 101 16371 25531 2043 2003 1996 7273 2047 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 7273 -100 2095 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   tokens: [CLS] description what ' s the meaning of the latin battle cry : ad arm ##a , ad arm ##a . [SEP]\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   init_ids: 101 6412 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 1010 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   input_ids: 101 6412 2054 1005 1055 1996 3574 1997 1996 3763 2645 5390 1024 4748 2849 2050 103 4748 2849 2050 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1997 -100 -100 -100 -100 -100 -100 -100 -100 1010 -100 2849 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   tokens: [CLS] description what are faults in the earth ' s crust ? [SEP]\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   init_ids: 101 6412 2054 2024 19399 1999 1996 3011 1005 1055 19116 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   input_ids: 101 6412 2054 2024 19399 1999 1996 3011 103 103 19116 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 1005 1055 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 19:16:26 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 19:16:26 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 19:16:26 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 19:16:26 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:59<00:00, 11.98s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.28s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.70it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.52it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.76it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.76it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.14it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.63it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.86it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.74it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.12it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.64it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.79it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=5, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 19:23:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 19:23:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 19:23:16 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 19:23:16 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 19:23:16 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 19:23:18 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 19:23:18 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 19:23:18 - INFO - __main__ -     Num examples = 16\n",
      "05/23/2021 19:23:18 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 19:23:18 - INFO - __main__ -     Num steps = 12\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.818974018096924\n",
      "Saving model. Best dev so far 4.818974018096924\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:25,  3.58s/it]Epoch 1, Dev loss 4.554498195648193\n",
      "Saving model. Best dev so far 4.554498195648193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|██▉                                  | 2/25 [00:06<01:19,  3.47s/it]Epoch 2, Dev loss 4.32623815536499\n",
      "Saving model. Best dev so far 4.32623815536499\n",
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:18,  3.57s/it]Epoch 3, Dev loss 4.104227066040039\n",
      "Saving model. Best dev so far 4.104227066040039\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:13<01:13,  3.48s/it]Epoch 4, Dev loss 3.881763458251953\n",
      "Saving model. Best dev so far 3.881763458251953\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:08,  3.43s/it]Epoch 5, Dev loss 3.682682514190674\n",
      "Saving model. Best dev so far 3.682682514190674\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:20<01:04,  3.40s/it]Epoch 6, Dev loss 3.5154056549072266\n",
      "Saving model. Best dev so far 3.5154056549072266\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:00,  3.38s/it]Epoch 7, Dev loss 3.397547960281372\n",
      "Saving model. Best dev so far 3.397547960281372\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:27<00:57,  3.38s/it]Epoch 8, Dev loss 3.3172924518585205\n",
      "Saving model. Best dev so far 3.3172924518585205\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:30<00:53,  3.37s/it]Epoch 9, Dev loss 3.26157546043396\n",
      "Saving model. Best dev so far 3.26157546043396\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:50,  3.37s/it]Epoch 10, Dev loss 3.2220370769500732\n",
      "Saving model. Best dev so far 3.2220370769500732\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:37<00:47,  3.36s/it]Epoch 11, Dev loss 3.1933095455169678\n",
      "Saving model. Best dev so far 3.1933095455169678\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:40<00:43,  3.36s/it]Epoch 12, Dev loss 3.171880006790161\n",
      "Saving model. Best dev so far 3.171880006790161\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:44<00:40,  3.35s/it]Epoch 13, Dev loss 3.153862476348877\n",
      "Saving model. Best dev so far 3.153862476348877\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:47<00:36,  3.36s/it]Epoch 14, Dev loss 3.138218402862549\n",
      "Saving model. Best dev so far 3.138218402862549\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:50<00:33,  3.35s/it]Epoch 15, Dev loss 3.1238439083099365\n",
      "Saving model. Best dev so far 3.1238439083099365\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:54<00:30,  3.38s/it]Epoch 16, Dev loss 3.111011266708374\n",
      "Saving model. Best dev so far 3.111011266708374\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:57<00:26,  3.37s/it]Epoch 17, Dev loss 3.0994367599487305\n",
      "Saving model. Best dev so far 3.0994367599487305\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:00<00:23,  3.36s/it]Epoch 18, Dev loss 3.0895445346832275\n",
      "Saving model. Best dev so far 3.0895445346832275\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:04<00:20,  3.36s/it]Epoch 19, Dev loss 3.0827667713165283\n",
      "Saving model. Best dev so far 3.0827667713165283\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:08<00:17,  3.52s/it]Epoch 20, Dev loss 3.0793979167938232\n",
      "Saving model. Best dev so far 3.0793979167938232\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:12<00:14,  3.69s/it]Epoch 21, Dev loss 3.0792784690856934\n",
      "Saving model. Best dev so far 3.0792784690856934\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:15<00:10,  3.61s/it]Epoch 22, Dev loss 3.0824804306030273\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:18<00:06,  3.40s/it]Epoch 23, Dev loss 3.089491605758667\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:21<00:03,  3.27s/it]Epoch 24, Dev loss 3.10044002532959\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:24<00:00,  3.38s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.18it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.84it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.55it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.76it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.51it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.11it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.46it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.86it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.65it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.01it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.60it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/bt', sample_num=1, seed=5, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.92it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.72it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.54it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.04it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.10it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.00it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.82it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.01it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 19:32:05 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 19:32:06 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 19:32:06 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 19:32:06 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 19:32:08 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 19:32:08 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   tokens: [CLS] what brand number grace ##s the black label of a bottle of jack daniel ' s ? [SEP]\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   init_ids: 101 2054 4435 2193 4519 2015 1996 2304 3830 1997 1037 5835 1997 2990 3817 1005 1055 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   input_ids: 101 2054 4435 103 4519 103 1996 2304 3830 1997 1037 5835 1997 2990 3817 1005 1055 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2193 -100 2015 -100 -100 -100 -100 -100 -100 -100 -100 -100 1005 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   tokens: [CLS] when was child labor abolished ? [SEP]\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   init_ids: 101 2043 2001 2775 4450 8961 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   input_ids: 101 2043 2001 2043 4450 8961 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2775 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   tokens: [CLS] what are the most common causes of death in the u . s . ? [SEP]\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   init_ids: 101 2054 2024 1996 2087 2691 5320 1997 2331 1999 1996 1057 1012 1055 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   input_ids: 101 2054 2024 103 103 2691 5320 1997 2331 1999 1996 1057 1012 1055 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 1996 2087 -100 -100 -100 -100 -100 -100 -100 -100 -100 1012 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   tokens: [CLS] how do i find info about rice import ##ers in the world ? [SEP]\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   init_ids: 101 2129 2079 1045 2424 18558 2055 5785 12324 2545 1999 1996 2088 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   input_ids: 101 2129 2079 103 2424 18558 2055 5785 103 2545 1999 1996 2088 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 1045 -100 -100 -100 -100 12324 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:32:08 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 19:32:08 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 19:32:08 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 19:32:08 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:59<00:00, 11.99s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.05it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.26s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.18it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.73it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.25it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.97it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.98it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.96it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.70it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 19:38:19 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 19:38:19 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 19:38:19 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 19:38:20 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 19:38:22 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 19:38:22 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 19:38:22 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   tokens: [CLS] numeric what brand number grace ##s the black label of a bottle of jack daniel ' s ? [SEP]\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   init_ids: 101 30522 2054 4435 2193 4519 2015 1996 2304 3830 1997 1037 5835 1997 2990 3817 1005 1055 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   input_ids: 101 30522 2054 4435 103 4519 103 1996 2304 3830 1997 1037 5835 1997 2990 3817 1005 1055 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2193 -100 2015 -100 -100 -100 -100 -100 -100 -100 -100 -100 1005 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   tokens: [CLS] numeric when was child labor abolished ? [SEP]\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   init_ids: 101 30522 2043 2001 2775 4450 8961 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   input_ids: 101 30522 2043 2001 2043 4450 8961 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2775 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   tokens: [CLS] description what are the most common causes of death in the u . s . ? [SEP]\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   init_ids: 101 6412 2054 2024 1996 2087 2691 5320 1997 2331 1999 1996 1057 1012 1055 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   input_ids: 101 6412 2054 2024 103 103 2691 5320 1997 2331 1999 1996 1057 1012 1055 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1996 2087 -100 -100 -100 -100 -100 -100 -100 -100 -100 1012 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   tokens: [CLS] description how do i find info about rice import ##ers in the world ? [SEP]\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   init_ids: 101 6412 2129 2079 1045 2424 18558 2055 5785 12324 2545 1999 1996 2088 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   input_ids: 101 6412 2129 2079 103 2424 18558 2055 5785 103 2545 1999 1996 2088 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 19:38:22 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1045 -100 -100 -100 -100 12324 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23/2021 19:38:22 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 19:38:22 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 19:38:22 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 19:38:22 - INFO - __main__ -     Num steps = 1125\n",
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:33<00:00, 11.82s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.55it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.86it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.66it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.03it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.82it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.92it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.47it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.91it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.20it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.83it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_5_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 20:12:20 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 20:12:21 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 20:12:21 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 20:12:21 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 20:12:23 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 20:12:23 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   tokens: [CLS] nu ##meric what brand number grace ##s the black label of a bottle of jack daniel ' s ? [SEP]\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   init_ids: 101 16371 25531 2054 4435 2193 4519 2015 1996 2304 3830 1997 1037 5835 1997 2990 3817 1005 1055 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   input_ids: 101 16371 25531 2054 4435 103 4519 103 1996 2304 3830 1997 1037 5835 1997 2990 3817 1005 1055 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 2193 -100 2015 -100 -100 -100 -100 -100 -100 -100 -100 -100 1005 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   tokens: [CLS] nu ##meric when was child labor abolished ? [SEP]\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   init_ids: 101 16371 25531 2043 2001 2775 4450 8961 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   input_ids: 101 16371 25531 103 2001 2043 4450 8961 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2043 -100 2775 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   tokens: [CLS] description what are the most common causes of death in the u . s . ? [SEP]\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   init_ids: 101 6412 2054 2024 1996 2087 2691 5320 1997 2331 1999 1996 1057 1012 1055 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   input_ids: 101 6412 2054 2024 103 103 2691 5320 1997 2331 1999 1996 1057 1012 1055 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1996 2087 -100 -100 -100 -100 -100 -100 -100 -100 -100 1012 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   tokens: [CLS] description how do i find info about rice import ##ers in the world ? [SEP]\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   init_ids: 101 6412 2129 2079 1045 2424 18558 2055 5785 12324 2545 1999 1996 2088 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   input_ids: 101 6412 2129 2079 103 2424 18558 2055 5785 103 2545 1999 1996 2088 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1045 -100 -100 -100 -100 12324 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:12:23 - INFO - __main__ -   label_len: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23/2021 20:12:23 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 20:12:23 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 20:12:23 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 20:12:23 - INFO - __main__ -     Num steps = 75\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:58<00:00, 11.89s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.67it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.73it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.96it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.30it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.99it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.22it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.03it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.93it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.97it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=6, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 20:18:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 20:18:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 20:18:33 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 20:18:33 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 20:18:33 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 20:18:36 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 20:18:36 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 20:18:36 - INFO - __main__ -     Num examples = 17\n",
      "05/23/2021 20:18:36 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 20:18:36 - INFO - __main__ -     Num steps = 13\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.873249053955078\n",
      "Saving model. Best dev so far 4.873249053955078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:23,  3.48s/it]Epoch 1, Dev loss 4.583181381225586\n",
      "Saving model. Best dev so far 4.583181381225586\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:06<01:19,  3.44s/it]Epoch 2, Dev loss 4.330050945281982\n",
      "Saving model. Best dev so far 4.330050945281982\n",
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:17,  3.54s/it]Epoch 3, Dev loss 4.082485198974609\n",
      "Saving model. Best dev so far 4.082485198974609\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:14<01:13,  3.51s/it]Epoch 4, Dev loss 3.834282159805298\n",
      "Saving model. Best dev so far 3.834282159805298\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:09,  3.47s/it]Epoch 5, Dev loss 3.621644973754883\n",
      "Saving model. Best dev so far 3.621644973754883\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:20<01:05,  3.44s/it]Epoch 6, Dev loss 3.4373204708099365\n",
      "Saving model. Best dev so far 3.4373204708099365\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:01,  3.43s/it]Epoch 7, Dev loss 3.3060245513916016\n",
      "Saving model. Best dev so far 3.3060245513916016\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:27<00:58,  3.43s/it]Epoch 8, Dev loss 3.2244107723236084\n",
      "Saving model. Best dev so far 3.2244107723236084\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:31<00:54,  3.42s/it]Epoch 9, Dev loss 3.1685750484466553\n",
      "Saving model. Best dev so far 3.1685750484466553\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:51,  3.41s/it]Epoch 10, Dev loss 3.1287875175476074\n",
      "Saving model. Best dev so far 3.1287875175476074\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:37<00:48,  3.43s/it]Epoch 11, Dev loss 3.10083270072937\n",
      "Saving model. Best dev so far 3.10083270072937\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:41<00:44,  3.43s/it]Epoch 12, Dev loss 3.080587387084961\n",
      "Saving model. Best dev so far 3.080587387084961\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:44<00:41,  3.42s/it]Epoch 13, Dev loss 3.063910961151123\n",
      "Saving model. Best dev so far 3.063910961151123\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:48<00:37,  3.42s/it]Epoch 14, Dev loss 3.048513650894165\n",
      "Saving model. Best dev so far 3.048513650894165\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:51<00:34,  3.42s/it]Epoch 15, Dev loss 3.0336015224456787\n",
      "Saving model. Best dev so far 3.0336015224456787\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:55<00:31,  3.49s/it]Epoch 16, Dev loss 3.019806146621704\n",
      "Saving model. Best dev so far 3.019806146621704\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:58<00:27,  3.46s/it]Epoch 17, Dev loss 3.0077431201934814\n",
      "Saving model. Best dev so far 3.0077431201934814\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:01<00:24,  3.44s/it]Epoch 18, Dev loss 2.999109983444214\n",
      "Saving model. Best dev so far 2.999109983444214\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:05<00:20,  3.46s/it]Epoch 19, Dev loss 2.9935007095336914\n",
      "Saving model. Best dev so far 2.9935007095336914\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:08<00:17,  3.44s/it]Epoch 20, Dev loss 2.9917116165161133\n",
      "Saving model. Best dev so far 2.9917116165161133\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:12<00:13,  3.44s/it]Epoch 21, Dev loss 2.9938368797302246\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:15<00:10,  3.38s/it]Epoch 22, Dev loss 2.9992778301239014\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:19<00:06,  3.41s/it]Epoch 23, Dev loss 3.009025812149048\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:22<00:03,  3.30s/it]Epoch 24, Dev loss 3.02213978767395\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:25<00:00,  3.40s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.02it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:14<00:00,  4.25it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.76it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.01it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.23it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.03it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.14it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.01it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.17it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.86it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.88it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.99it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.62it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/bt', sample_num=1, seed=6, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.73it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.68it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.86it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.98it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.77it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.22it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.64it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.13it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  4.00it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.74it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.05it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.71it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.59it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.13it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 20:28:18 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 20:28:19 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 20:28:19 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 20:28:19 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 20:28:21 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 20:28:21 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   tokens: [CLS] what was joe nam ##ath ' s first contract worth ? [SEP]\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   init_ids: 101 2054 2001 3533 15125 8988 1005 1055 2034 3206 4276 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   input_ids: 101 2054 2001 3533 15125 8988 103 1055 2034 103 4276 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 1005 -100 -100 3206 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   tokens: [CLS] what is the size of the largest ak ##ita ? [SEP]\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   init_ids: 101 2054 2003 1996 2946 1997 1996 2922 17712 6590 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   input_ids: 101 2054 2003 1996 2946 1997 103 2922 17712 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 1996 -100 -100 6590 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   tokens: [CLS] how did ` stat ' come to be used as an expression for quickly ? [SEP]\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   init_ids: 101 2129 2106 1036 28093 1005 2272 2000 2022 2109 2004 2019 3670 2005 2855 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   input_ids: 101 2129 2106 1036 28093 1005 2272 103 2022 2272 2004 2019 3670 2005 2855 2109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 2000 -100 2109 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   tokens: [CLS] what does the name ` ` she ##ri ' ' mean ? [SEP]\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   init_ids: 101 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 2812 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   input_ids: 101 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 1036 -100 -100 -100 -100 2812 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:28:21 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 20:28:21 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 20:28:21 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 20:28:21 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:01<00:00, 12.14s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.14it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.69it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.01it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.50it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.73it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.71it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.86it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.00it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.04it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.02it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 20:34:48 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 20:34:48 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 20:34:48 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 20:34:49 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 20:34:51 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 20:34:51 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 20:34:51 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   tokens: [CLS] numeric what was joe nam ##ath ' s first contract worth ? [SEP]\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   init_ids: 101 30522 2054 2001 3533 15125 8988 1005 1055 2034 3206 4276 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   input_ids: 101 30522 2054 2001 3533 15125 8988 103 1055 2034 103 4276 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1005 -100 -100 3206 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   tokens: [CLS] numeric what is the size of the largest ak ##ita ? [SEP]\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   init_ids: 101 30522 2054 2003 1996 2946 1997 1996 2922 17712 6590 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   input_ids: 101 30522 2054 2003 1996 2946 1997 103 2922 17712 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1996 -100 -100 6590 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   tokens: [CLS] description how did ` stat ' come to be used as an expression for quickly ? [SEP]\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   init_ids: 101 6412 2129 2106 1036 28093 1005 2272 2000 2022 2109 2004 2019 3670 2005 2855 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   input_ids: 101 6412 2129 2106 1036 28093 1005 2272 103 2022 2272 2004 2019 3670 2005 2855 2109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 2000 -100 2109 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   tokens: [CLS] description what does the name ` ` she ##ri ' ' mean ? [SEP]\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   init_ids: 101 6412 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 2812 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   input_ids: 101 6412 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1036 -100 -100 -100 -100 2812 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 20:34:51 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 20:34:51 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 20:34:51 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 20:34:51 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:45<00:00, 11.91s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.47it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:14<00:00,  4.22it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.65it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.14it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.56it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.80it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.18it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.31it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.02it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_6_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 21:08:28 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 21:08:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 21:08:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 21:08:29 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 21:08:31 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 21:08:31 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   tokens: [CLS] nu ##meric what was joe nam ##ath ' s first contract worth ? [SEP]\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2001 3533 15125 8988 1005 1055 2034 3206 4276 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   input_ids: 101 16371 25531 2054 2001 3533 15125 8988 103 1055 2034 103 4276 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 1005 -100 -100 3206 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   tokens: [CLS] nu ##meric what is the size of the largest ak ##ita ? [SEP]\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2003 1996 2946 1997 1996 2922 17712 6590 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   input_ids: 101 16371 25531 2054 2003 1996 2946 1997 103 2922 17712 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 1996 -100 -100 6590 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   tokens: [CLS] description how did ` stat ' come to be used as an expression for quickly ? [SEP]\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   init_ids: 101 6412 2129 2106 1036 28093 1005 2272 2000 2022 2109 2004 2019 3670 2005 2855 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   input_ids: 101 6412 2129 2106 1036 28093 1005 2272 103 2022 2272 2004 2019 3670 2005 2855 2109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 2000 -100 2109 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   tokens: [CLS] description what does the name ` ` she ##ri ' ' mean ? [SEP]\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   init_ids: 101 6412 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 2812 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   input_ids: 101 6412 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1036 -100 -100 -100 -100 2812 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 21:08:31 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 21:08:31 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 21:08:31 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 21:08:31 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:58<00:00, 11.84s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.54it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.84it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.01it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.97it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.83it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.00it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.96it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.86it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=7, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 21:14:54 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 21:14:54 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 21:14:55 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 21:14:55 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 21:14:55 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 21:14:58 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 21:14:58 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 21:14:58 - INFO - __main__ -     Num examples = 17\n",
      "05/23/2021 21:14:58 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 21:14:58 - INFO - __main__ -     Num steps = 13\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.9092488288879395\n",
      "Saving model. Best dev so far 4.9092488288879395\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:26,  3.58s/it]Epoch 1, Dev loss 4.625919818878174\n",
      "Saving model. Best dev so far 4.625919818878174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|██▉                                  | 2/25 [00:07<01:21,  3.56s/it]Epoch 2, Dev loss 4.375253677368164\n",
      "Saving model. Best dev so far 4.375253677368164\n",
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:16,  3.49s/it]Epoch 3, Dev loss 4.129515171051025\n",
      "Saving model. Best dev so far 4.129515171051025\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:14<01:14,  3.53s/it]Epoch 4, Dev loss 3.8875505924224854\n",
      "Saving model. Best dev so far 3.8875505924224854\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:09,  3.48s/it]Epoch 5, Dev loss 3.68107533454895\n",
      "Saving model. Best dev so far 3.68107533454895\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:20<01:05,  3.45s/it]Epoch 6, Dev loss 3.4976608753204346\n",
      "Saving model. Best dev so far 3.4976608753204346\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:01,  3.43s/it]Epoch 7, Dev loss 3.35420298576355\n",
      "Saving model. Best dev so far 3.35420298576355\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:28<00:59,  3.52s/it]Epoch 8, Dev loss 3.2616665363311768\n",
      "Saving model. Best dev so far 3.2616665363311768\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:31<00:55,  3.49s/it]Epoch 9, Dev loss 3.199664354324341\n",
      "Saving model. Best dev so far 3.199664354324341\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:51,  3.46s/it]Epoch 10, Dev loss 3.156994342803955\n",
      "Saving model. Best dev so far 3.156994342803955\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:38<00:48,  3.45s/it]Epoch 11, Dev loss 3.1242916584014893\n",
      "Saving model. Best dev so far 3.1242916584014893\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:41<00:44,  3.44s/it]Epoch 12, Dev loss 3.0969924926757812\n",
      "Saving model. Best dev so far 3.0969924926757812\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:45<00:41,  3.43s/it]Epoch 13, Dev loss 3.072293519973755\n",
      "Saving model. Best dev so far 3.072293519973755\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:48<00:37,  3.42s/it]Epoch 14, Dev loss 3.048973798751831\n",
      "Saving model. Best dev so far 3.048973798751831\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:51<00:34,  3.43s/it]Epoch 15, Dev loss 3.0262386798858643\n",
      "Saving model. Best dev so far 3.0262386798858643\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:55<00:30,  3.43s/it]Epoch 16, Dev loss 3.0043108463287354\n",
      "Saving model. Best dev so far 3.0043108463287354\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:58<00:27,  3.42s/it]Epoch 17, Dev loss 2.986314058303833\n",
      "Saving model. Best dev so far 2.986314058303833\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:02<00:23,  3.41s/it]Epoch 18, Dev loss 2.97234845161438\n",
      "Saving model. Best dev so far 2.97234845161438\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:05<00:20,  3.41s/it]Epoch 19, Dev loss 2.962088108062744\n",
      "Saving model. Best dev so far 2.962088108062744\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:09<00:17,  3.51s/it]Epoch 20, Dev loss 2.954977512359619\n",
      "Saving model. Best dev so far 2.954977512359619\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:12<00:13,  3.48s/it]Epoch 21, Dev loss 2.9508204460144043\n",
      "Saving model. Best dev so far 2.9508204460144043\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:16<00:10,  3.48s/it]Epoch 22, Dev loss 2.950035572052002\n",
      "Saving model. Best dev so far 2.950035572052002\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:19<00:06,  3.45s/it]Epoch 23, Dev loss 2.9521143436431885\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:22<00:03,  3.31s/it]Epoch 24, Dev loss 2.957202196121216\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:25<00:00,  3.42s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.62it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.70it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.03it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.27it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.94it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.43it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.93it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.62it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.51it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/bt', sample_num=1, seed=7, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.11it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.74it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.60it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.22it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.81it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.84it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.25it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.21it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.23it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.67it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.98it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 21:24:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 21:24:16 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 21:24:16 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 21:24:16 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 21:24:18 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 21:24:18 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   tokens: [CLS] what are the chances of pre ##gna ##cy if the penis does not penetrate the va ##gina ? [SEP]\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   init_ids: 101 2054 2024 1996 9592 1997 3653 16989 5666 2065 1996 19085 2515 2025 19136 1996 12436 20876 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   input_ids: 101 2054 2024 103 9592 1997 3653 16989 5666 2065 1996 19085 2515 2025 19136 103 12436 20876 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 1996 -100 -100 -100 -100 -100 -100 1996 -100 -100 -100 -100 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   tokens: [CLS] when was florida admitted into the union ? [SEP]\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   init_ids: 101 2043 2001 3516 4914 2046 1996 2586 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   input_ids: 101 2043 103 3516 4914 2046 1996 2586 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   masked_lm_labels: -100 -100 2001 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   tokens: [CLS] how do doctors dia ##gno ##se bone cancer ? [SEP]\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   init_ids: 101 2129 2079 7435 22939 26745 3366 5923 4456 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   input_ids: 101 2129 103 7435 22939 26745 3366 103 4456 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   masked_lm_labels: -100 -100 2079 -100 -100 -100 -100 5923 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   tokens: [CLS] why is microsoft ' s windows 3 software so successful ? [SEP]\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   init_ids: 101 2339 2003 7513 1005 1055 3645 1017 4007 2061 3144 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   input_ids: 101 2339 2003 103 1005 1055 103 1017 4007 2061 3144 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 7513 -100 -100 3645 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:24:18 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 21:24:18 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 21:24:18 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 21:24:18 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:59<00:00, 11.99s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.28s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.92it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.15it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.27it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.62it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.99it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.96it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.98it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.93it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 21:30:23 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 21:30:24 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 21:30:24 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 21:30:24 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 21:30:26 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 21:30:26 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 21:30:26 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   tokens: [CLS] numeric what are the chances of pre ##gna ##cy if the penis does not penetrate the va ##gina ? [SEP]\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   init_ids: 101 30522 2054 2024 1996 9592 1997 3653 16989 5666 2065 1996 19085 2515 2025 19136 1996 12436 20876 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   input_ids: 101 30522 2054 2024 103 9592 1997 3653 16989 5666 2065 1996 19085 2515 2025 19136 103 12436 20876 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1996 -100 -100 -100 -100 -100 -100 1996 -100 -100 -100 -100 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   tokens: [CLS] numeric when was florida admitted into the union ? [SEP]\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   init_ids: 101 30522 2043 2001 3516 4914 2046 1996 2586 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   input_ids: 101 30522 2043 103 3516 4914 2046 1996 2586 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2001 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   tokens: [CLS] description how do doctors dia ##gno ##se bone cancer ? [SEP]\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   init_ids: 101 6412 2129 2079 7435 22939 26745 3366 5923 4456 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   input_ids: 101 6412 2129 103 7435 22939 26745 3366 103 4456 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2079 -100 -100 -100 -100 5923 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   tokens: [CLS] description why is microsoft ' s windows 3 software so successful ? [SEP]\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   init_ids: 101 6412 2339 2003 7513 1005 1055 3645 1017 4007 2061 3144 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   input_ids: 101 6412 2339 2003 103 1005 1055 103 1017 4007 2061 3144 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 7513 -100 -100 3645 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 21:30:27 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 21:30:27 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 21:30:27 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 21:30:27 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:48<00:00, 11.92s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.12it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.99it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.80it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.94it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.45it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.08s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.82it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.53it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.91it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.82it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.30it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_7_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 22:04:19 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 22:04:19 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 22:04:19 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 22:04:20 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 22:04:22 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 22:04:22 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   tokens: [CLS] nu ##meric what are the chances of pre ##gna ##cy if the penis does not penetrate the va ##gina ? [SEP]\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2024 1996 9592 1997 3653 16989 5666 2065 1996 19085 2515 2025 19136 1996 12436 20876 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   input_ids: 101 16371 25531 2054 2024 103 9592 1997 3653 16989 5666 2065 1996 19085 2515 2025 19136 103 12436 20876 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 1996 -100 -100 -100 -100 -100 -100 1996 -100 -100 -100 -100 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   tokens: [CLS] nu ##meric when was florida admitted into the union ? [SEP]\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   init_ids: 101 16371 25531 2043 2001 3516 4914 2046 1996 2586 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   input_ids: 101 16371 25531 2043 103 3516 4914 2046 1996 2586 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2001 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   tokens: [CLS] description how do doctors dia ##gno ##se bone cancer ? [SEP]\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   init_ids: 101 6412 2129 2079 7435 22939 26745 3366 5923 4456 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   input_ids: 101 6412 2129 103 7435 22939 26745 3366 103 4456 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2079 -100 -100 -100 -100 5923 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   tokens: [CLS] description why is microsoft ' s windows 3 software so successful ? [SEP]\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   init_ids: 101 6412 2339 2003 7513 1005 1055 3645 1017 4007 2061 3144 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   input_ids: 101 6412 2339 2003 103 1005 1055 103 1017 4007 2061 3144 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 7513 -100 -100 3645 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 22:04:22 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 22:04:22 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 22:04:22 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 22:04:22 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:58<00:00, 11.83s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.96it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.94it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.14it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.44it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.75it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.62it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.67it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.12it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.45it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.49it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=8, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 22:10:28 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 22:10:28 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 22:10:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 22:10:29 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 22:10:29 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 22:10:32 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 22:10:32 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 22:10:32 - INFO - __main__ -     Num examples = 17\n",
      "05/23/2021 22:10:32 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 22:10:32 - INFO - __main__ -     Num steps = 13\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.888926982879639\n",
      "Saving model. Best dev so far 4.888926982879639\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:24,  3.53s/it]Epoch 1, Dev loss 4.598677635192871\n",
      "Saving model. Best dev so far 4.598677635192871\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:07<01:21,  3.53s/it]Epoch 2, Dev loss 4.348696231842041\n",
      "Saving model. Best dev so far 4.348696231842041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:17,  3.54s/it]Epoch 3, Dev loss 4.104134559631348\n",
      "Saving model. Best dev so far 4.104134559631348\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:14<01:13,  3.52s/it]Epoch 4, Dev loss 3.8666954040527344\n",
      "Saving model. Best dev so far 3.8666954040527344\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:09,  3.49s/it]Epoch 5, Dev loss 3.6735196113586426\n",
      "Saving model. Best dev so far 3.6735196113586426\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:21<01:06,  3.49s/it]Epoch 6, Dev loss 3.5049993991851807\n",
      "Saving model. Best dev so far 3.5049993991851807\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:02,  3.48s/it]Epoch 7, Dev loss 3.367501974105835\n",
      "Saving model. Best dev so far 3.367501974105835\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:28<00:59,  3.49s/it]Epoch 8, Dev loss 3.274022102355957\n",
      "Saving model. Best dev so far 3.274022102355957\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:31<00:55,  3.49s/it]Epoch 9, Dev loss 3.2079122066497803\n",
      "Saving model. Best dev so far 3.2079122066497803\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:52,  3.48s/it]Epoch 10, Dev loss 3.1614580154418945\n",
      "Saving model. Best dev so far 3.1614580154418945\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:38<00:48,  3.48s/it]Epoch 11, Dev loss 3.130260467529297\n",
      "Saving model. Best dev so far 3.130260467529297\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:42<00:45,  3.51s/it]Epoch 12, Dev loss 3.1067161560058594\n",
      "Saving model. Best dev so far 3.1067161560058594\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:45<00:42,  3.51s/it]Epoch 13, Dev loss 3.0858070850372314\n",
      "Saving model. Best dev so far 3.0858070850372314\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:49<00:38,  3.51s/it]Epoch 14, Dev loss 3.0661098957061768\n",
      "Saving model. Best dev so far 3.0661098957061768\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:52<00:35,  3.50s/it]Epoch 15, Dev loss 3.0474307537078857\n",
      "Saving model. Best dev so far 3.0474307537078857\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:55<00:31,  3.50s/it]Epoch 16, Dev loss 3.0294861793518066\n",
      "Saving model. Best dev so far 3.0294861793518066\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:59<00:28,  3.51s/it]Epoch 17, Dev loss 3.013561725616455\n",
      "Saving model. Best dev so far 3.013561725616455\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:03<00:24,  3.50s/it]Epoch 18, Dev loss 2.9996249675750732\n",
      "Saving model. Best dev so far 2.9996249675750732\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:06<00:20,  3.49s/it]Epoch 19, Dev loss 2.9887595176696777\n",
      "Saving model. Best dev so far 2.9887595176696777\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:09<00:17,  3.49s/it]Epoch 20, Dev loss 2.9811630249023438\n",
      "Saving model. Best dev so far 2.9811630249023438\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:13<00:13,  3.48s/it]Epoch 21, Dev loss 2.976118564605713\n",
      "Saving model. Best dev so far 2.976118564605713\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:16<00:10,  3.47s/it]Epoch 22, Dev loss 2.974924087524414\n",
      "Saving model. Best dev so far 2.974924087524414\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:20<00:06,  3.47s/it]Epoch 23, Dev loss 2.9768853187561035\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:23<00:03,  3.35s/it]Epoch 24, Dev loss 2.983487844467163\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:26<00:00,  3.46s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.95it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.82it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.78it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.65it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.62it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.74it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.95it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:16<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.86it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.85it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.83it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/bt', sample_num=1, seed=8, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.76it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.57it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.84it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.52it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.29it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.00it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.89it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.26it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.65it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 22:19:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 22:19:32 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 22:19:32 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 22:19:33 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 22:19:35 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 22:19:35 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   tokens: [CLS] how many bones are in the human hand ? [SEP]\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   init_ids: 101 2129 2116 5944 2024 1999 1996 2529 2192 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   input_ids: 101 2129 2116 5944 2024 103 1996 2529 2192 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 5944 -100 1999 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   tokens: [CLS] hitler came to power in germany in what year ? [SEP]\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   init_ids: 101 8042 2234 2000 2373 1999 2762 1999 2054 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   input_ids: 101 8042 2234 103 2373 1999 2762 1999 2054 2095 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2000 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   tokens: [CLS] what is the golden rule ? [SEP]\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   init_ids: 101 2054 2003 1996 3585 3627 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   input_ids: 101 2054 2003 1996 3585 3627 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   tokens: [CLS] what is the che ##mi ##os ##mot ##ic theory ? [SEP]\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   init_ids: 101 2054 2003 1996 18178 4328 2891 18938 2594 3399 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   input_ids: 101 103 2003 1996 18178 4328 103 18938 2594 3399 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   masked_lm_labels: -100 2054 -100 -100 -100 -100 2891 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:19:35 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 22:19:35 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 22:19:35 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 22:19:35 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:00<00:00, 12.07s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.27s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.53it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.72it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.73it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.95it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.25it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.90it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.96it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.64it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.90it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.20it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.74it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 22:26:00 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 22:26:01 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 22:26:01 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 22:26:01 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 22:26:04 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 22:26:04 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 22:26:04 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   tokens: [CLS] numeric how many bones are in the human hand ? [SEP]\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   init_ids: 101 30522 2129 2116 5944 2024 1999 1996 2529 2192 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   input_ids: 101 30522 2129 2116 5944 2024 103 1996 2529 2192 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 5944 -100 1999 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   tokens: [CLS] numeric hitler came to power in germany in what year ? [SEP]\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   init_ids: 101 30522 8042 2234 2000 2373 1999 2762 1999 2054 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   input_ids: 101 30522 8042 2234 103 2373 1999 2762 1999 2054 2095 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2000 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   tokens: [CLS] description what is the golden rule ? [SEP]\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   init_ids: 101 6412 2054 2003 1996 3585 3627 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   input_ids: 101 6412 2054 2003 1996 3585 3627 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   tokens: [CLS] description what is the che ##mi ##os ##mot ##ic theory ? [SEP]\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   init_ids: 101 6412 2054 2003 1996 18178 4328 2891 18938 2594 3399 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   input_ids: 101 6412 103 2003 1996 18178 4328 103 18938 2594 3399 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 -100 -100 -100 -100 2891 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:26:04 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 22:26:04 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 22:26:04 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 22:26:04 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:37<00:00, 11.85s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.27s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.97it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.81it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.75it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.10it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.11it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.36it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.07it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.78it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.14it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_8_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 22:59:52 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 22:59:53 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 22:59:53 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 22:59:53 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 22:59:55 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 22:59:55 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   tokens: [CLS] nu ##meric how many bones are in the human hand ? [SEP]\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   init_ids: 101 16371 25531 2129 2116 5944 2024 1999 1996 2529 2192 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   input_ids: 101 16371 25531 2129 2116 5944 2024 103 1996 2529 2192 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 5944 -100 1999 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   tokens: [CLS] nu ##meric hitler came to power in germany in what year ? [SEP]\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   init_ids: 101 16371 25531 8042 2234 2000 2373 1999 2762 1999 2054 2095 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   input_ids: 101 16371 25531 8042 2234 103 2373 1999 2762 1999 2054 2095 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 2000 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   tokens: [CLS] description what is the golden rule ? [SEP]\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   init_ids: 101 6412 2054 2003 1996 3585 3627 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   input_ids: 101 6412 2054 2003 1996 3585 3627 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   tokens: [CLS] description what is the che ##mi ##os ##mot ##ic theory ? [SEP]\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   init_ids: 101 6412 2054 2003 1996 18178 4328 2891 18938 2594 3399 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   input_ids: 101 6412 103 2003 1996 18178 4328 103 18938 2594 3399 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 -100 -100 -100 -100 2891 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 22:59:55 - INFO - __main__ -   ***** Running training *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23/2021 22:59:55 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 22:59:55 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 22:59:55 - INFO - __main__ -     Num steps = 75\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:58<00:00, 11.84s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.56it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.44it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.04it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.97it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.65it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.98it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.76it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.14it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.12it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=9, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/23/2021 23:06:19 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/23/2021 23:06:19 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/23/2021 23:06:20 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/23/2021 23:06:20 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/23/2021 23:06:20 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/23/2021 23:06:23 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/23/2021 23:06:23 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 23:06:23 - INFO - __main__ -     Num examples = 17\n",
      "05/23/2021 23:06:23 - INFO - __main__ -     Batch size = 32\n",
      "05/23/2021 23:06:23 - INFO - __main__ -     Num steps = 13\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.916412830352783\n",
      "Saving model. Best dev so far 4.916412830352783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:27,  3.63s/it]Epoch 1, Dev loss 4.637639045715332\n",
      "Saving model. Best dev so far 4.637639045715332\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:07<01:23,  3.62s/it]Epoch 2, Dev loss 4.392892837524414\n",
      "Saving model. Best dev so far 4.392892837524414\n",
      "Epoch:  12%|████▍                                | 3/25 [00:10<01:18,  3.55s/it]Epoch 3, Dev loss 4.1562018394470215\n",
      "Saving model. Best dev so far 4.1562018394470215\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:14<01:13,  3.52s/it]Epoch 4, Dev loss 3.9202849864959717\n",
      "Saving model. Best dev so far 3.9202849864959717\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:17<01:10,  3.50s/it]Epoch 5, Dev loss 3.7169954776763916\n",
      "Saving model. Best dev so far 3.7169954776763916\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:21<01:06,  3.49s/it]Epoch 6, Dev loss 3.543900728225708\n",
      "Saving model. Best dev so far 3.543900728225708\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:02,  3.48s/it]Epoch 7, Dev loss 3.403549909591675\n",
      "Saving model. Best dev so far 3.403549909591675\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:28<00:59,  3.48s/it]Epoch 8, Dev loss 3.3075649738311768\n",
      "Saving model. Best dev so far 3.3075649738311768\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:31<00:56,  3.50s/it]Epoch 9, Dev loss 3.2389957904815674\n",
      "Saving model. Best dev so far 3.2389957904815674\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:35<00:52,  3.49s/it]Epoch 10, Dev loss 3.1918675899505615\n",
      "Saving model. Best dev so far 3.1918675899505615\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:38<00:49,  3.51s/it]Epoch 11, Dev loss 3.158834934234619\n",
      "Saving model. Best dev so far 3.158834934234619\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:42<00:45,  3.49s/it]Epoch 12, Dev loss 3.1335201263427734\n",
      "Saving model. Best dev so far 3.1335201263427734\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:45<00:41,  3.48s/it]Epoch 13, Dev loss 3.1132848262786865\n",
      "Saving model. Best dev so far 3.1132848262786865\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:49<00:38,  3.49s/it]Epoch 14, Dev loss 3.0955758094787598\n",
      "Saving model. Best dev so far 3.0955758094787598\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:52<00:34,  3.48s/it]Epoch 15, Dev loss 3.0801172256469727\n",
      "Saving model. Best dev so far 3.0801172256469727\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:55<00:31,  3.48s/it]Epoch 16, Dev loss 3.066239595413208\n",
      "Saving model. Best dev so far 3.066239595413208\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:59<00:28,  3.51s/it]Epoch 17, Dev loss 3.054837703704834\n",
      "Saving model. Best dev so far 3.054837703704834\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:03<00:24,  3.50s/it]Epoch 18, Dev loss 3.0473525524139404\n",
      "Saving model. Best dev so far 3.0473525524139404\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:06<00:20,  3.49s/it]Epoch 19, Dev loss 3.0440356731414795\n",
      "Saving model. Best dev so far 3.0440356731414795\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:10<00:17,  3.50s/it]Epoch 20, Dev loss 3.0427052974700928\n",
      "Saving model. Best dev so far 3.0427052974700928\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:13<00:13,  3.49s/it]Epoch 21, Dev loss 3.044804811477661\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:16<00:10,  3.36s/it]Epoch 22, Dev loss 3.050525665283203\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:19<00:06,  3.26s/it]Epoch 23, Dev loss 3.059877634048462\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:22<00:03,  3.19s/it]Epoch 24, Dev loss 3.074431896209717\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:25<00:00,  3.43s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.12it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.22it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.99it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.90it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.30it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.98it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.61it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/bt', sample_num=1, seed=9, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.90it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.98it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.76it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.70it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.07it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.72it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:14<00:00,  4.20it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.73it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.80it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.95it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 23:15:20 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 23:15:20 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 23:15:20 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 23:15:21 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 23:15:23 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 23:15:23 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   tokens: [CLS] how many games are played in a five - team round - robin tournament ? [SEP]\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   init_ids: 101 2129 2116 2399 2024 2209 1999 1037 2274 1011 2136 2461 1011 5863 2977 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   input_ids: 101 2129 1011 2399 2024 2209 1999 1037 2274 1011 2136 2461 1011 5863 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   masked_lm_labels: -100 -100 2116 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 2977 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   tokens: [CLS] what month were you born in if your births ##tone is sar ##don ##yx ? [SEP]\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   init_ids: 101 2054 3204 2020 2017 2141 1999 2065 2115 18250 5524 2003 18906 5280 17275 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   input_ids: 101 2054 3204 2020 2017 103 1999 2065 103 18250 103 2003 18906 5280 17275 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 2141 -100 -100 2115 -100 5524 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   tokens: [CLS] what are my legal rights in an automobile rep ##oss ##ess ##ion in california ? [SEP]\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   init_ids: 101 2054 2024 2026 3423 2916 1999 2019 9935 16360 15094 7971 3258 1999 2662 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   input_ids: 101 2054 3258 2026 3423 2916 1999 2019 9935 16360 15094 7971 3258 1999 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   masked_lm_labels: -100 -100 2024 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 2662 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   tokens: [CLS] what is use ##net for the internet ? [SEP]\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   init_ids: 101 2054 2003 2224 7159 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   input_ids: 101 2054 2003 2224 7159 2005 103 4274 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:15:23 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 1996 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23/2021 23:15:23 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 23:15:23 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 23:15:23 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 23:15:23 - INFO - __main__ -     Num steps = 75\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:58<00:00, 11.88s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.96it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.77it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.92it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.91it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.70it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.94it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.86it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.90it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.56it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.82it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.51it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.58it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 23:21:46 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 23:21:47 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 23:21:47 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 23:21:48 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 23:21:50 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 23:21:50 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 23:21:50 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   tokens: [CLS] numeric how many games are played in a five - team round - robin tournament ? [SEP]\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   init_ids: 101 30522 2129 2116 2399 2024 2209 1999 1037 2274 1011 2136 2461 1011 5863 2977 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   input_ids: 101 30522 2129 1011 2399 2024 2209 1999 1037 2274 1011 2136 2461 1011 5863 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2116 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 2977 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   tokens: [CLS] numeric what month were you born in if your births ##tone is sar ##don ##yx ? [SEP]\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   init_ids: 101 30522 2054 3204 2020 2017 2141 1999 2065 2115 18250 5524 2003 18906 5280 17275 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   input_ids: 101 30522 2054 3204 2020 2017 103 1999 2065 103 18250 103 2003 18906 5280 17275 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 2141 -100 -100 2115 -100 5524 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   tokens: [CLS] description what are my legal rights in an automobile rep ##oss ##ess ##ion in california ? [SEP]\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   init_ids: 101 6412 2054 2024 2026 3423 2916 1999 2019 9935 16360 15094 7971 3258 1999 2662 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   input_ids: 101 6412 2054 3258 2026 3423 2916 1999 2019 9935 16360 15094 7971 3258 1999 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2024 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 2662 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   tokens: [CLS] description what is use ##net for the internet ? [SEP]\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   init_ids: 101 6412 2054 2003 2224 7159 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   input_ids: 101 6412 2054 2003 2224 7159 2005 103 4274 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1996 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:21:50 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 23:21:50 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 23:21:50 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 23:21:50 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [29:40<00:00, 11.87s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.84it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.57it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.00it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.47it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.01it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.13it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.84it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.95it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.46it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.43it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_9_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/23/2021 23:56:10 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/23/2021 23:56:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/23/2021 23:56:11 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/23/2021 23:56:11 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/23/2021 23:56:13 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/23/2021 23:56:13 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   guid: train-0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   tokens: [CLS] nu ##meric how many games are played in a five - team round - robin tournament ? [SEP]\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   init_ids: 101 16371 25531 2129 2116 2399 2024 2209 1999 1037 2274 1011 2136 2461 1011 5863 2977 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   input_ids: 101 16371 25531 2129 1011 2399 2024 2209 1999 1037 2274 1011 2136 2461 1011 5863 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2116 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 2977 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   guid: train-1\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   tokens: [CLS] nu ##meric what month were you born in if your births ##tone is sar ##don ##yx ? [SEP]\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   init_ids: 101 16371 25531 2054 3204 2020 2017 2141 1999 2065 2115 18250 5524 2003 18906 5280 17275 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   input_ids: 101 16371 25531 2054 3204 2020 2017 103 1999 2065 103 18250 103 2003 18906 5280 17275 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 2141 -100 -100 2115 -100 5524 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   label_len: 2\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   guid: dev-0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   tokens: [CLS] description what are my legal rights in an automobile rep ##oss ##ess ##ion in california ? [SEP]\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   init_ids: 101 6412 2054 2024 2026 3423 2916 1999 2019 9935 16360 15094 7971 3258 1999 2662 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   input_ids: 101 6412 2054 3258 2026 3423 2916 1999 2019 9935 16360 15094 7971 3258 1999 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2024 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 2662 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   label_len: 1\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   *** Example ***\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   guid: dev-1\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   tokens: [CLS] description what is use ##net for the internet ? [SEP]\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   init_ids: 101 6412 2054 2003 2224 7159 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   input_ids: 101 6412 2054 2003 2224 7159 2005 103 4274 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 1996 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/23/2021 23:56:13 - INFO - __main__ -   label_len: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23/2021 23:56:13 - INFO - __main__ -   ***** Running training *****\n",
      "05/23/2021 23:56:13 - INFO - __main__ -     Num examples = 60\n",
      "05/23/2021 23:56:13 - INFO - __main__ -     Batch size = 8\n",
      "05/23/2021 23:56:13 - INFO - __main__ -     Num steps = 75\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:58<00:00, 11.86s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.44it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.07it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.59it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.70it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.65it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.73it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.93it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.03it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.90it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.73it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.29s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=10, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/24/2021 00:03:00 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/24/2021 00:03:00 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/24/2021 00:03:01 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/24/2021 00:03:01 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/24/2021 00:03:01 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/24/2021 00:03:03 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/24/2021 00:03:04 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 00:03:04 - INFO - __main__ -     Num examples = 16\n",
      "05/24/2021 00:03:04 - INFO - __main__ -     Batch size = 32\n",
      "05/24/2021 00:03:04 - INFO - __main__ -     Num steps = 12\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Dev loss 4.933502674102783\n",
      "Saving model. Best dev so far 4.933502674102783\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:34,  3.93s/it]Epoch 1, Dev loss 4.653980255126953\n",
      "Saving model. Best dev so far 4.653980255126953\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:08<01:33,  4.06s/it]Epoch 2, Dev loss 4.408871650695801\n",
      "Saving model. Best dev so far 4.408871650695801\n",
      "Epoch:  12%|████▍                                | 3/25 [00:11<01:22,  3.77s/it]Epoch 3, Dev loss 4.163421630859375\n",
      "Saving model. Best dev so far 4.163421630859375\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:14<01:15,  3.59s/it]Epoch 4, Dev loss 3.9182047843933105\n",
      "Saving model. Best dev so far 3.9182047843933105\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:18<01:10,  3.50s/it]Epoch 5, Dev loss 3.6992969512939453\n",
      "Saving model. Best dev so far 3.6992969512939453\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:21<01:05,  3.45s/it]Epoch 6, Dev loss 3.5237905979156494\n",
      "Saving model. Best dev so far 3.5237905979156494\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:01,  3.43s/it]Epoch 7, Dev loss 3.4144537448883057\n",
      "Saving model. Best dev so far 3.4144537448883057\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:28<00:58,  3.42s/it]Epoch 8, Dev loss 3.3429346084594727\n",
      "Saving model. Best dev so far 3.3429346084594727\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:31<00:54,  3.39s/it]Epoch 9, Dev loss 3.292323112487793\n",
      "Saving model. Best dev so far 3.292323112487793\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:34<00:50,  3.37s/it]Epoch 10, Dev loss 3.2539937496185303\n",
      "Saving model. Best dev so far 3.2539937496185303\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:38<00:47,  3.37s/it]Epoch 11, Dev loss 3.222153663635254\n",
      "Saving model. Best dev so far 3.222153663635254\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:41<00:43,  3.35s/it]Epoch 12, Dev loss 3.196035623550415\n",
      "Saving model. Best dev so far 3.196035623550415\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:45<00:40,  3.36s/it]Epoch 13, Dev loss 3.1741559505462646\n",
      "Saving model. Best dev so far 3.1741559505462646\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:48<00:36,  3.34s/it]Epoch 14, Dev loss 3.155982255935669\n",
      "Saving model. Best dev so far 3.155982255935669\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:51<00:33,  3.33s/it]Epoch 15, Dev loss 3.140606641769409\n",
      "Saving model. Best dev so far 3.140606641769409\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:54<00:29,  3.32s/it]Epoch 16, Dev loss 3.127643585205078\n",
      "Saving model. Best dev so far 3.127643585205078\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [00:58<00:26,  3.31s/it]Epoch 17, Dev loss 3.1169352531433105\n",
      "Saving model. Best dev so far 3.1169352531433105\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:01<00:24,  3.46s/it]Epoch 18, Dev loss 3.1087749004364014\n",
      "Saving model. Best dev so far 3.1087749004364014\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:05<00:20,  3.42s/it]Epoch 19, Dev loss 3.1032395362854004\n",
      "Saving model. Best dev so far 3.1032395362854004\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:08<00:16,  3.38s/it]Epoch 20, Dev loss 3.101259469985962\n",
      "Saving model. Best dev so far 3.101259469985962\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:11<00:13,  3.36s/it]Epoch 21, Dev loss 3.104525566101074\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:14<00:09,  3.23s/it]Epoch 22, Dev loss 3.1127068996429443\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:17<00:06,  3.13s/it]Epoch 23, Dev loss 3.125204563140869\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:20<00:03,  3.09s/it]Epoch 24, Dev loss 3.141235113143921\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:23<00:00,  3.35s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.25it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.90it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:20<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.71it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.89it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.46it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.90it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.49it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.01it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.14it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.50it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.01it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.28s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.73it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/bt', sample_num=1, seed=10, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.61it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.61it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.91it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.03it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.00it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.05it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.92it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.07s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.68it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.99it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.88it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.20it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.86it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 00:12:01 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 00:12:02 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 00:12:02 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 00:12:03 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 00:12:05 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 00:12:05 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   tokens: [CLS] what is the current ticket fare from from cairo to barbados ? [SEP]\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   init_ids: 101 2054 2003 1996 2783 7281 13258 2013 2013 11096 2000 16893 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   input_ids: 101 2054 2003 1996 2783 7281 13258 2013 2013 103 2000 16893 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 11096 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   tokens: [CLS] how many characters makes up a word for typing test purposes ? [SEP]\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   init_ids: 101 2129 2116 3494 3084 2039 1037 2773 2005 22868 3231 5682 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   input_ids: 101 2129 2116 3494 3084 2039 1037 2773 2005 103 3231 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 22868 -100 5682 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   tokens: [CLS] what does the name ` ` she ##ri ' ' mean ? [SEP]\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   init_ids: 101 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 2812 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   input_ids: 101 2054 2515 1996 2171 1036 1036 2016 3089 103 1005 2812 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 1005 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   tokens: [CLS] what does storm wave mean in japanese ? [SEP]\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   init_ids: 101 2054 2515 4040 4400 2812 1999 2887 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   input_ids: 101 2054 2515 4040 103 103 1999 2887 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 4400 2812 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:12:05 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 00:12:05 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 00:12:05 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 00:12:05 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [01:59<00:00, 11.99s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.47it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.03it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.74it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.71it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.75it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:18<00:00,  3.45it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.61it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.51it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.76it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.30s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.46it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.81it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 00:18:04 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 00:18:05 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 00:18:05 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 00:18:05 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 00:18:08 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 00:18:08 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 00:18:08 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   tokens: [CLS] numeric what is the current ticket fare from from cairo to barbados ? [SEP]\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   init_ids: 101 30522 2054 2003 1996 2783 7281 13258 2013 2013 11096 2000 16893 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   input_ids: 101 30522 2054 2003 1996 2783 7281 13258 2013 2013 103 2000 16893 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 11096 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   tokens: [CLS] numeric how many characters makes up a word for typing test purposes ? [SEP]\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   init_ids: 101 30522 2129 2116 3494 3084 2039 1037 2773 2005 22868 3231 5682 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   input_ids: 101 30522 2129 2116 3494 3084 2039 1037 2773 2005 103 3231 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 22868 -100 5682 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   tokens: [CLS] description what does the name ` ` she ##ri ' ' mean ? [SEP]\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   init_ids: 101 6412 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 2812 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   input_ids: 101 6412 2054 2515 1996 2171 1036 1036 2016 3089 103 1005 2812 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 1005 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   tokens: [CLS] description what does storm wave mean in japanese ? [SEP]\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   init_ids: 101 6412 2054 2515 4040 4400 2812 1999 2887 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   input_ids: 101 6412 2054 2515 4040 103 103 1999 2887 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 4400 2812 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:18:08 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 00:18:08 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 00:18:08 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 00:18:08 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [30:25<00:00, 12.17s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.24s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.77it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.83it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.23it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.69it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.09it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.15it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.95it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.16it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.65it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.45it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.50it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.95it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.01it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_10_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 00:53:17 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 00:53:18 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 00:53:18 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 00:53:18 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 00:53:20 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 00:53:20 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   tokens: [CLS] nu ##meric what is the current ticket fare from from cairo to barbados ? [SEP]\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2003 1996 2783 7281 13258 2013 2013 11096 2000 16893 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   input_ids: 101 16371 25531 2054 2003 1996 2783 7281 13258 2013 2013 103 2000 16893 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 11096 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   tokens: [CLS] nu ##meric how many characters makes up a word for typing test purposes ? [SEP]\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   init_ids: 101 16371 25531 2129 2116 3494 3084 2039 1037 2773 2005 22868 3231 5682 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   input_ids: 101 16371 25531 2129 2116 3494 3084 2039 1037 2773 2005 103 3231 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 22868 -100 5682 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   tokens: [CLS] description what does the name ` ` she ##ri ' ' mean ? [SEP]\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   init_ids: 101 6412 2054 2515 1996 2171 1036 1036 2016 3089 1005 1005 2812 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   input_ids: 101 6412 2054 2515 1996 2171 1036 1036 2016 3089 103 1005 2812 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 1005 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   tokens: [CLS] description what does storm wave mean in japanese ? [SEP]\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   init_ids: 101 6412 2054 2515 4040 4400 2812 1999 2887 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   input_ids: 101 6412 2054 2515 4040 103 103 1999 2887 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 4400 2812 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 00:53:20 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 00:53:20 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 00:53:20 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 00:53:20 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:01<00:00, 12.11s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.20it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.81it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.79it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.40it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.67it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.88it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.87it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.18s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.97it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.19s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.35it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.88it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=11, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/24/2021 00:59:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/24/2021 00:59:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/24/2021 00:59:32 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/24/2021 00:59:32 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/24/2021 00:59:32 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/24/2021 00:59:35 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/24/2021 00:59:35 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 00:59:35 - INFO - __main__ -     Num examples = 17\n",
      "05/24/2021 00:59:35 - INFO - __main__ -     Batch size = 32\n",
      "05/24/2021 00:59:35 - INFO - __main__ -     Num steps = 13\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.837757587432861\n",
      "Saving model. Best dev so far 4.837757587432861\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:03<01:31,  3.81s/it]Epoch 1, Dev loss 4.566037178039551\n",
      "Saving model. Best dev so far 4.566037178039551\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:07<01:27,  3.80s/it]Epoch 2, Dev loss 4.328701496124268\n",
      "Saving model. Best dev so far 4.328701496124268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▍                                | 3/25 [00:11<01:20,  3.64s/it]Epoch 3, Dev loss 4.097418785095215\n",
      "Saving model. Best dev so far 4.097418785095215\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:14<01:15,  3.60s/it]Epoch 4, Dev loss 3.8685410022735596\n",
      "Saving model. Best dev so far 3.8685410022735596\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:18<01:10,  3.54s/it]Epoch 5, Dev loss 3.6718525886535645\n",
      "Saving model. Best dev so far 3.6718525886535645\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:21<01:06,  3.50s/it]Epoch 6, Dev loss 3.506629705429077\n",
      "Saving model. Best dev so far 3.506629705429077\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:24<01:02,  3.48s/it]Epoch 7, Dev loss 3.368299722671509\n",
      "Saving model. Best dev so far 3.368299722671509\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:28<00:59,  3.51s/it]Epoch 8, Dev loss 3.2682552337646484\n",
      "Saving model. Best dev so far 3.2682552337646484\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:31<00:55,  3.50s/it]Epoch 9, Dev loss 3.197493314743042\n",
      "Saving model. Best dev so far 3.197493314743042\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:35<00:52,  3.48s/it]Epoch 10, Dev loss 3.1494228839874268\n",
      "Saving model. Best dev so far 3.1494228839874268\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:38<00:48,  3.46s/it]Epoch 11, Dev loss 3.113403558731079\n",
      "Saving model. Best dev so far 3.113403558731079\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:42<00:44,  3.45s/it]Epoch 12, Dev loss 3.083836555480957\n",
      "Saving model. Best dev so far 3.083836555480957\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:45<00:41,  3.42s/it]Epoch 13, Dev loss 3.058387279510498\n",
      "Saving model. Best dev so far 3.058387279510498\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [00:49<00:38,  3.53s/it]Epoch 14, Dev loss 3.0354816913604736\n",
      "Saving model. Best dev so far 3.0354816913604736\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [00:52<00:34,  3.50s/it]Epoch 15, Dev loss 3.0149929523468018\n",
      "Saving model. Best dev so far 3.0149929523468018\n",
      "Epoch:  64%|███████████████████████             | 16/25 [00:56<00:32,  3.57s/it]Epoch 16, Dev loss 2.9970343112945557\n",
      "Saving model. Best dev so far 2.9970343112945557\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [01:00<00:28,  3.59s/it]Epoch 17, Dev loss 2.9824180603027344\n",
      "Saving model. Best dev so far 2.9824180603027344\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:04<00:26,  3.81s/it]Epoch 18, Dev loss 2.9711852073669434\n",
      "Saving model. Best dev so far 2.9711852073669434\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:07<00:22,  3.70s/it]Epoch 19, Dev loss 2.964486837387085\n",
      "Saving model. Best dev so far 2.964486837387085\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:11<00:18,  3.62s/it]Epoch 20, Dev loss 2.9617295265197754\n",
      "Saving model. Best dev so far 2.9617295265197754\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:14<00:14,  3.55s/it]Epoch 21, Dev loss 2.9631285667419434\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:17<00:10,  3.38s/it]Epoch 22, Dev loss 2.9660229682922363\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:20<00:06,  3.26s/it]Epoch 23, Dev loss 2.972691535949707\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:23<00:03,  3.18s/it]Epoch 24, Dev loss 2.982685089111328\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:26<00:00,  3.47s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.31it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.12it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.14s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.96it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.62it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.67it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.22s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.76it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.32it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.94it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:17<00:00,  3.58it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.05it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/bt', sample_num=1, seed=11, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.23s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.07it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.75it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.85it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.54it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  3.97it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.76it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.05it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.50it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.80it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.48it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:15<00:00,  4.01it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:01<00:00,  4.08it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:16<00:00,  3.91it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 01:09:10 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 01:09:10 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 01:09:10 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 01:09:11 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 01:09:13 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 01:09:13 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   tokens: [CLS] what year did the vietnam war end ? [SEP]\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   init_ids: 101 2054 2095 2106 1996 5148 2162 2203 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   input_ids: 101 103 103 2106 1996 5148 2162 2203 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   masked_lm_labels: -100 2054 2095 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   tokens: [CLS] how many times larger than life size is the statue of liberty ? [SEP]\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   init_ids: 101 2129 2116 2335 3469 2084 2166 2946 2003 1996 6231 1997 7044 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   input_ids: 101 2129 2116 2335 2116 2084 2166 103 2003 1996 6231 1997 7044 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 3469 -100 -100 2946 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   tokens: [CLS] what should you yell to hail a taxi in madrid ? [SEP]\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   init_ids: 101 2054 2323 2017 14315 2000 16889 1037 10095 1999 6921 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   input_ids: 101 103 2323 2017 103 2000 16889 1037 10095 1999 6921 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   masked_lm_labels: -100 2054 -100 -100 14315 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   tokens: [CLS] why were red m & ms discontinued then brought back ? [SEP]\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   init_ids: 101 2339 2020 2417 1049 1004 5796 8944 2059 2716 2067 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   input_ids: 101 2339 2020 2417 1049 1004 5796 8944 2059 2716 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:09:13 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 5796 -100 -100 -100 2067 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/24/2021 01:09:13 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 01:09:13 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 01:09:13 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 01:09:13 - INFO - __main__ -     Num steps = 75\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:31<00:00, 15.13s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:22<00:00,  1.47s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.04it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 01:17:08 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 01:17:09 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 01:17:09 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 01:17:09 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 01:17:11 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 01:17:11 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 01:17:11 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   tokens: [CLS] numeric what year did the vietnam war end ? [SEP]\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   init_ids: 101 30522 2054 2095 2106 1996 5148 2162 2203 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   input_ids: 101 30522 103 103 2106 1996 5148 2162 2203 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 2095 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   tokens: [CLS] numeric how many times larger than life size is the statue of liberty ? [SEP]\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   init_ids: 101 30522 2129 2116 2335 3469 2084 2166 2946 2003 1996 6231 1997 7044 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   input_ids: 101 30522 2129 2116 2335 2116 2084 2166 103 2003 1996 6231 1997 7044 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 3469 -100 -100 2946 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   tokens: [CLS] description what should you yell to hail a taxi in madrid ? [SEP]\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   init_ids: 101 6412 2054 2323 2017 14315 2000 16889 1037 10095 1999 6921 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   input_ids: 101 6412 103 2323 2017 103 2000 16889 1037 10095 1999 6921 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 -100 -100 14315 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   tokens: [CLS] description why were red m & ms discontinued then brought back ? [SEP]\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   init_ids: 101 6412 2339 2020 2417 1049 1004 5796 8944 2059 2716 2067 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   input_ids: 101 6412 2339 2020 2417 1049 1004 5796 8944 2059 2716 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 5796 -100 -100 -100 2067 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 01:17:12 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 01:17:12 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 01:17:12 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 01:17:12 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [38:23<00:00, 15.36s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:20<00:00,  1.39s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.04it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:20<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:20<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_11_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 02:00:36 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 02:00:36 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 02:00:36 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 02:00:36 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 02:00:39 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 02:00:39 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   tokens: [CLS] nu ##meric what year did the vietnam war end ? [SEP]\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2095 2106 1996 5148 2162 2203 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   input_ids: 101 16371 25531 103 103 2106 1996 5148 2162 2203 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2054 2095 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   tokens: [CLS] nu ##meric how many times larger than life size is the statue of liberty ? [SEP]\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   init_ids: 101 16371 25531 2129 2116 2335 3469 2084 2166 2946 2003 1996 6231 1997 7044 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   input_ids: 101 16371 25531 2129 2116 2335 2116 2084 2166 103 2003 1996 6231 1997 7044 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 3469 -100 -100 2946 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   tokens: [CLS] description what should you yell to hail a taxi in madrid ? [SEP]\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   init_ids: 101 6412 2054 2323 2017 14315 2000 16889 1037 10095 1999 6921 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   input_ids: 101 6412 103 2323 2017 103 2000 16889 1037 10095 1999 6921 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 -100 -100 14315 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   tokens: [CLS] description why were red m & ms discontinued then brought back ? [SEP]\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   init_ids: 101 6412 2339 2020 2417 1049 1004 5796 8944 2059 2716 2067 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   input_ids: 101 6412 2339 2020 2417 1049 1004 5796 8944 2059 2716 103 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 5796 -100 -100 -100 2067 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 02:00:39 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 02:00:39 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 02:00:39 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 02:00:39 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:35<00:00, 15.51s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.31it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.28it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.31it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.03it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.04it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=12, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/24/2021 02:08:38 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/24/2021 02:08:38 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/24/2021 02:08:39 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/24/2021 02:08:39 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/24/2021 02:08:39 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/24/2021 02:08:42 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/24/2021 02:08:42 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 02:08:42 - INFO - __main__ -     Num examples = 16\n",
      "05/24/2021 02:08:42 - INFO - __main__ -     Batch size = 32\n",
      "05/24/2021 02:08:42 - INFO - __main__ -     Num steps = 12\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.8701171875\n",
      "Saving model. Best dev so far 4.8701171875\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:04<01:43,  4.31s/it]Epoch 1, Dev loss 4.577524662017822\n",
      "Saving model. Best dev so far 4.577524662017822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|██▉                                  | 2/25 [00:08<01:39,  4.33s/it]Epoch 2, Dev loss 4.317220687866211\n",
      "Saving model. Best dev so far 4.317220687866211\n",
      "Epoch:  12%|████▍                                | 3/25 [00:13<01:35,  4.35s/it]Epoch 3, Dev loss 4.054688930511475\n",
      "Saving model. Best dev so far 4.054688930511475\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:17<01:33,  4.47s/it]Epoch 4, Dev loss 3.7892465591430664\n",
      "Saving model. Best dev so far 3.7892465591430664\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:21<01:27,  4.38s/it]Epoch 5, Dev loss 3.545285224914551\n",
      "Saving model. Best dev so far 3.545285224914551\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:26<01:22,  4.36s/it]Epoch 6, Dev loss 3.354403495788574\n",
      "Saving model. Best dev so far 3.354403495788574\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:30<01:18,  4.34s/it]Epoch 7, Dev loss 3.239849805831909\n",
      "Saving model. Best dev so far 3.239849805831909\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:35<01:16,  4.47s/it]Epoch 8, Dev loss 3.1682775020599365\n",
      "Saving model. Best dev so far 3.1682775020599365\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:39<01:12,  4.54s/it]Epoch 9, Dev loss 3.1161158084869385\n",
      "Saving model. Best dev so far 3.1161158084869385\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:44<01:07,  4.48s/it]Epoch 10, Dev loss 3.075460195541382\n",
      "Saving model. Best dev so far 3.075460195541382\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:48<01:01,  4.42s/it]Epoch 11, Dev loss 3.0420539379119873\n",
      "Saving model. Best dev so far 3.0420539379119873\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:52<00:57,  4.39s/it]Epoch 12, Dev loss 3.014273166656494\n",
      "Saving model. Best dev so far 3.014273166656494\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:57<00:52,  4.35s/it]Epoch 13, Dev loss 2.9905576705932617\n",
      "Saving model. Best dev so far 2.9905576705932617\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [01:01<00:47,  4.34s/it]Epoch 14, Dev loss 2.969322681427002\n",
      "Saving model. Best dev so far 2.969322681427002\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [01:05<00:42,  4.29s/it]Epoch 15, Dev loss 2.951413869857788\n",
      "Saving model. Best dev so far 2.951413869857788\n",
      "Epoch:  64%|███████████████████████             | 16/25 [01:09<00:38,  4.30s/it]Epoch 16, Dev loss 2.9357855319976807\n",
      "Saving model. Best dev so far 2.9357855319976807\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [01:14<00:34,  4.29s/it]Epoch 17, Dev loss 2.924283742904663\n",
      "Saving model. Best dev so far 2.924283742904663\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:18<00:30,  4.29s/it]Epoch 18, Dev loss 2.916067361831665\n",
      "Saving model. Best dev so far 2.916067361831665\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:22<00:25,  4.28s/it]Epoch 19, Dev loss 2.910092353820801\n",
      "Saving model. Best dev so far 2.910092353820801\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:27<00:21,  4.28s/it]Epoch 20, Dev loss 2.905444622039795\n",
      "Saving model. Best dev so far 2.905444622039795\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:31<00:16,  4.25s/it]Epoch 21, Dev loss 2.902707576751709\n",
      "Saving model. Best dev so far 2.902707576751709\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:35<00:12,  4.24s/it]Epoch 22, Dev loss 2.9027247428894043\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:39<00:08,  4.11s/it]Epoch 23, Dev loss 2.904569387435913\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:43<00:04,  4.04s/it]Epoch 24, Dev loss 2.9106853008270264\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:47<00:00,  4.28s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.10it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/bt', sample_num=1, seed=12, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:11<00:00,  1.39s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.03it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.37s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.35s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.34s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.04it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.37s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.34s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.01it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.31it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.03it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 02:19:09 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 02:19:10 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 02:19:10 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 02:19:10 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 02:19:12 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 02:19:12 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   tokens: [CLS] how loud is thunder ? [SEP]\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   init_ids: 101 2129 5189 2003 8505 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   input_ids: 101 103 5189 2003 8505 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   masked_lm_labels: -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   tokens: [CLS] what are the highest - paying odds on a ro ##ule ##tte table ? [SEP]\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   init_ids: 101 2054 2024 1996 3284 1011 7079 10238 2006 1037 20996 9307 4674 2795 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   input_ids: 101 2054 2024 103 3284 1011 7079 10238 2006 1037 103 9307 4674 2795 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 1996 -100 -100 -100 -100 -100 -100 20996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   tokens: [CLS] how did socrates die ? [SEP]\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   init_ids: 101 2129 2106 26772 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   input_ids: 101 103 2106 26772 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   masked_lm_labels: -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   tokens: [CLS] what is the distinction of er ##le stanley gardner ' s the case of the terrified ty ##pis ##t ? [SEP]\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   init_ids: 101 2054 2003 1996 7835 1997 9413 2571 6156 11764 1005 1055 1996 2553 1997 1996 10215 5939 18136 2102 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   input_ids: 101 2054 2003 1996 7835 103 9413 2571 6156 11764 1005 1055 1996 103 1997 1996 10215 5939 103 2102 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 1997 -100 -100 -100 -100 -100 -100 -100 2553 -100 -100 -100 -100 18136 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:19:12 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 02:19:12 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 02:19:12 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 02:19:12 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:32<00:00, 15.22s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:22<00:00,  1.49s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.42it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.04it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 02:27:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 02:27:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 02:27:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 02:27:30 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 02:27:32 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 02:27:32 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 02:27:32 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   tokens: [CLS] numeric how loud is thunder ? [SEP]\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   init_ids: 101 30522 2129 5189 2003 8505 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   input_ids: 101 30522 103 5189 2003 8505 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   masked_lm_labels: -100 -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   tokens: [CLS] numeric what are the highest - paying odds on a ro ##ule ##tte table ? [SEP]\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   init_ids: 101 30522 2054 2024 1996 3284 1011 7079 10238 2006 1037 20996 9307 4674 2795 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   input_ids: 101 30522 2054 2024 103 3284 1011 7079 103 2006 1037 103 9307 4674 2795 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 1996 -100 -100 -100 10238 -100 -100 20996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   tokens: [CLS] description how did socrates die ? [SEP]\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   init_ids: 101 6412 2129 2106 26772 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   input_ids: 101 6412 103 2106 26772 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   masked_lm_labels: -100 -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   tokens: [CLS] description what is the distinction of er ##le stanley gardner ' s the case of the terrified ty ##pis ##t ? [SEP]\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   init_ids: 101 6412 2054 2003 1996 7835 1997 9413 2571 6156 11764 1005 1055 1996 2553 1997 1996 10215 5939 18136 2102 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   input_ids: 101 6412 2054 2003 1996 7835 103 9413 2571 6156 11764 1005 1055 1996 103 1997 1996 10215 5939 103 2102 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 02:27:32 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 1997 -100 -100 -100 -100 -100 -100 -100 2553 -100 -100 -100 -100 18136 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/24/2021 02:27:32 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 02:27:32 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 02:27:32 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 02:27:32 - INFO - __main__ -     Num steps = 1125\n",
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [38:16<00:00, 15.31s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.42it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.42it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.10it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.10it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_12_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 03:11:11 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 03:11:12 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 03:11:12 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 03:11:12 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 03:11:15 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 03:11:15 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   tokens: [CLS] nu ##meric how loud is thunder ? [SEP]\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   init_ids: 101 16371 25531 2129 5189 2003 8505 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   input_ids: 101 16371 25531 103 5189 2003 8505 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   tokens: [CLS] nu ##meric what are the highest - paying odds on a ro ##ule ##tte table ? [SEP]\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2024 1996 3284 1011 7079 10238 2006 1037 20996 9307 4674 2795 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   input_ids: 101 16371 25531 2054 2024 103 3284 1011 7079 103 2006 1037 103 9307 4674 2795 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 1996 -100 -100 -100 10238 -100 -100 20996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   tokens: [CLS] description how did socrates die ? [SEP]\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   init_ids: 101 6412 2129 2106 26772 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   input_ids: 101 6412 103 2106 26772 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   masked_lm_labels: -100 -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   tokens: [CLS] description what is the distinction of er ##le stanley gardner ' s the case of the terrified ty ##pis ##t ? [SEP]\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   init_ids: 101 6412 2054 2003 1996 7835 1997 9413 2571 6156 11764 1005 1055 1996 2553 1997 1996 10215 5939 18136 2102 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   input_ids: 101 6412 2054 2003 1996 7835 103 9413 2571 6156 11764 1005 1055 1996 103 1997 1996 10215 5939 103 2102 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 1997 -100 -100 -100 -100 -100 -100 -100 2553 -100 -100 -100 -100 18136 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 03:11:15 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 03:11:15 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 03:11:15 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 03:11:15 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:31<00:00, 15.18s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:22<00:00,  1.48s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.03it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.45s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.33it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=13, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/24/2021 03:18:52 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/24/2021 03:18:52 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/24/2021 03:18:53 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/24/2021 03:18:53 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/24/2021 03:18:53 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/24/2021 03:18:56 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/24/2021 03:18:56 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 03:18:56 - INFO - __main__ -     Num examples = 16\n",
      "05/24/2021 03:18:56 - INFO - __main__ -     Batch size = 32\n",
      "05/24/2021 03:18:56 - INFO - __main__ -     Num steps = 12\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.695003032684326\n",
      "Saving model. Best dev so far 4.695003032684326\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:04<01:42,  4.29s/it]Epoch 1, Dev loss 4.416317939758301\n",
      "Saving model. Best dev so far 4.416317939758301\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:08<01:39,  4.33s/it]Epoch 2, Dev loss 4.179567337036133\n",
      "Saving model. Best dev so far 4.179567337036133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▍                                | 3/25 [00:12<01:35,  4.33s/it]Epoch 3, Dev loss 3.946349859237671\n",
      "Saving model. Best dev so far 3.946349859237671\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:17<01:30,  4.33s/it]Epoch 4, Dev loss 3.710880994796753\n",
      "Saving model. Best dev so far 3.710880994796753\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:21<01:26,  4.33s/it]Epoch 5, Dev loss 3.4988532066345215\n",
      "Saving model. Best dev so far 3.4988532066345215\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:25<01:22,  4.32s/it]Epoch 6, Dev loss 3.3159561157226562\n",
      "Saving model. Best dev so far 3.3159561157226562\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:30<01:17,  4.32s/it]Epoch 7, Dev loss 3.1912569999694824\n",
      "Saving model. Best dev so far 3.1912569999694824\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:34<01:13,  4.34s/it]Epoch 8, Dev loss 3.1076204776763916\n",
      "Saving model. Best dev so far 3.1076204776763916\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:39<01:10,  4.43s/it]Epoch 9, Dev loss 3.0457260608673096\n",
      "Saving model. Best dev so far 3.0457260608673096\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:43<01:05,  4.35s/it]Epoch 10, Dev loss 2.998218059539795\n",
      "Saving model. Best dev so far 2.998218059539795\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:47<01:00,  4.32s/it]Epoch 11, Dev loss 2.9614577293395996\n",
      "Saving model. Best dev so far 2.9614577293395996\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:51<00:56,  4.32s/it]Epoch 12, Dev loss 2.931863307952881\n",
      "Saving model. Best dev so far 2.931863307952881\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:56<00:51,  4.32s/it]Epoch 13, Dev loss 2.90779709815979\n",
      "Saving model. Best dev so far 2.90779709815979\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [01:00<00:47,  4.32s/it]Epoch 14, Dev loss 2.8870041370391846\n",
      "Saving model. Best dev so far 2.8870041370391846\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [01:04<00:43,  4.32s/it]Epoch 15, Dev loss 2.8690176010131836\n",
      "Saving model. Best dev so far 2.8690176010131836\n",
      "Epoch:  64%|███████████████████████             | 16/25 [01:09<00:38,  4.29s/it]Epoch 16, Dev loss 2.8538308143615723\n",
      "Saving model. Best dev so far 2.8538308143615723\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [01:13<00:34,  4.30s/it]Epoch 17, Dev loss 2.841756820678711\n",
      "Saving model. Best dev so far 2.841756820678711\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:17<00:30,  4.31s/it]Epoch 18, Dev loss 2.833770275115967\n",
      "Saving model. Best dev so far 2.833770275115967\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:22<00:26,  4.35s/it]Epoch 19, Dev loss 2.8281354904174805\n",
      "Saving model. Best dev so far 2.8281354904174805\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:26<00:22,  4.43s/it]Epoch 20, Dev loss 2.82499361038208\n",
      "Saving model. Best dev so far 2.82499361038208\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:31<00:17,  4.45s/it]Epoch 21, Dev loss 2.8247592449188232\n",
      "Saving model. Best dev so far 2.8247592449188232\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:35<00:13,  4.45s/it]Epoch 22, Dev loss 2.8284218311309814\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:39<00:08,  4.36s/it]Epoch 23, Dev loss 2.8356518745422363\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:44<00:04,  4.31s/it]Epoch 24, Dev loss 2.8470065593719482\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:48<00:00,  4.33s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:22<00:00,  1.47s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/bt', sample_num=1, seed=13, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:11<00:00,  1.39s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.34s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.37s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:11<00:00,  1.38s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.35s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.34s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 03:29:49 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 03:29:50 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 03:29:50 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 03:29:50 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 03:29:52 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 03:29:52 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   tokens: [CLS] what year did montana become a state ? [SEP]\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   init_ids: 101 2054 2095 2106 8124 2468 1037 2110 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   input_ids: 101 103 2095 2106 2110 2468 1037 2110 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   masked_lm_labels: -100 2054 -100 -100 8124 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   tokens: [CLS] when did the royal wedding of prince andrew and fe ##rg ##ie take place ? [SEP]\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   init_ids: 101 2043 2106 1996 2548 5030 1997 3159 4080 1998 10768 10623 2666 2202 2173 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   input_ids: 101 2043 2106 1996 2548 5030 1997 3159 103 1998 10768 10623 2666 103 2173 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   masked_lm_labels: -100 -100 2106 -100 -100 -100 -100 -100 4080 -100 -100 -100 -100 2202 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   tokens: [CLS] why do they call a hamburger a hamburger when there is no ham ? [SEP]\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   init_ids: 101 2339 2079 2027 2655 1037 24575 1037 24575 2043 2045 2003 2053 10654 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   input_ids: 101 2339 2079 2027 2655 1037 24575 1037 103 103 2045 2003 2053 10654 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 -100 -100 -100 24575 2043 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   tokens: [CLS] what type of childhood did jules ve ##rne have ? [SEP]\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   init_ids: 101 2054 2828 1997 5593 2106 11044 2310 12119 2031 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   input_ids: 101 2054 2828 1997 103 2106 11044 2310 2031 2031 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 5593 -100 -100 -100 12119 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:29:52 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 03:29:52 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 03:29:52 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 03:29:52 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:33<00:00, 15.35s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 03:37:48 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 03:37:48 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 03:37:48 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 03:37:49 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 03:37:51 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 03:37:51 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 03:37:51 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   tokens: [CLS] numeric what year did montana become a state ? [SEP]\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   init_ids: 101 30522 2054 2095 2106 8124 2468 1037 2110 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   input_ids: 101 30522 103 2095 2106 2110 2468 1037 2110 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 -100 -100 8124 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   tokens: [CLS] numeric when did the royal wedding of prince andrew and fe ##rg ##ie take place ? [SEP]\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   init_ids: 101 30522 2043 2106 1996 2548 5030 1997 3159 4080 1998 10768 10623 2666 2202 2173 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   input_ids: 101 30522 2043 2106 1996 2548 5030 1997 3159 103 1998 10768 10623 2666 103 2173 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2106 -100 -100 -100 -100 -100 4080 -100 -100 -100 -100 2202 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   tokens: [CLS] description why do they call a hamburger a hamburger when there is no ham ? [SEP]\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   init_ids: 101 6412 2339 2079 2027 2655 1037 24575 1037 24575 2043 2045 2003 2053 10654 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   input_ids: 101 6412 103 2079 2027 2655 1037 24575 1037 103 103 2045 2003 2053 10654 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   masked_lm_labels: -100 -100 2339 -100 -100 -100 -100 -100 -100 24575 2043 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   tokens: [CLS] description what type of childhood did jules ve ##rne have ? [SEP]\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   init_ids: 101 6412 2054 2828 1997 5593 2106 11044 2310 12119 2031 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   input_ids: 101 6412 2054 2828 1997 103 2106 11044 2310 2031 2031 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 03:37:51 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 5593 -100 -100 -100 12119 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/24/2021 03:37:51 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 03:37:51 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 03:37:51 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 03:37:51 - INFO - __main__ -     Num steps = 1125\n",
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [38:22<00:00, 15.35s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:20<00:00,  1.37s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.31s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.46it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.32s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.10it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.32s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.32s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.42it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.31s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.43it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.33s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.11it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:19<00:00,  1.32s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_13_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 04:21:04 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 04:21:04 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 04:21:04 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 04:21:04 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 04:21:07 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 04:21:07 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   tokens: [CLS] nu ##meric what year did montana become a state ? [SEP]\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   init_ids: 101 16371 25531 2054 2095 2106 8124 2468 1037 2110 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   input_ids: 101 16371 25531 103 2095 2106 2110 2468 1037 2110 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2054 -100 -100 8124 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   tokens: [CLS] nu ##meric when did the royal wedding of prince andrew and fe ##rg ##ie take place ? [SEP]\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   init_ids: 101 16371 25531 2043 2106 1996 2548 5030 1997 3159 4080 1998 10768 10623 2666 2202 2173 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   input_ids: 101 16371 25531 2043 2106 1996 2548 5030 1997 3159 103 1998 10768 10623 2666 103 2173 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 2106 -100 -100 -100 -100 -100 4080 -100 -100 -100 -100 2202 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   tokens: [CLS] description why do they call a hamburger a hamburger when there is no ham ? [SEP]\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   init_ids: 101 6412 2339 2079 2027 2655 1037 24575 1037 24575 2043 2045 2003 2053 10654 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   input_ids: 101 6412 103 2079 2027 2655 1037 24575 1037 103 103 2045 2003 2053 10654 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   masked_lm_labels: -100 -100 2339 -100 -100 -100 -100 -100 -100 24575 2043 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   tokens: [CLS] description what type of childhood did jules ve ##rne have ? [SEP]\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   init_ids: 101 6412 2054 2828 1997 5593 2106 11044 2310 12119 2031 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   input_ids: 101 6412 2054 2828 1997 103 2106 11044 2310 2031 2031 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 5593 -100 -100 -100 12119 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 04:21:07 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 04:21:07 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 04:21:07 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 04:21:07 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:36<00:00, 15.61s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.46s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.30it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.33it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.04it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.02it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.35it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.33it/s]\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/eda' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/eda.py\", line 68, in <module>\n",
      "    from nltk.corpus import wordnet\n",
      "ModuleNotFoundError: No module named 'nltk'\n",
      "usage: bert_classifier.py [-h] [--task {stsa,snips,trec}]\n",
      "                          [--data_dir DATA_DIR] [--seed SEED]\n",
      "                          [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                          [--warmup_steps WARMUP_STEPS]\n",
      "                          [--max_seq_length MAX_SEQ_LENGTH] [--cache CACHE]\n",
      "                          [--epochs EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                          [--learning_rate LEARNING_RATE]\n",
      "                          [--batch_size BATCH_SIZE]\n",
      "bert_classifier.py: error: argument --learning_rate: expected one argument\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/gpt2' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(block_size=64, cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10', gpu=0, learning_rate=4e-05, max_seq_length=64, num_train_epochs=25.0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/gpt2', prefix=3, repetition_penalty=1.0, sample_num=1, sample_ratio=7, seed=14, task_name='trec', temp=1.0, temperature=1.0, top_k=0, top_p=0.9, train_batch_size=32, warmup_proportion=0.1)\n",
      "05/24/2021 04:28:48 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/24/2021 04:28:48 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/24/2021 04:28:49 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/24/2021 04:28:49 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/24/2021 04:28:49 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/24/2021 04:28:51 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/24/2021 04:28:51 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 04:28:51 - INFO - __main__ -     Num examples = 16\n",
      "05/24/2021 04:28:51 - INFO - __main__ -     Batch size = 32\n",
      "05/24/2021 04:28:51 - INFO - __main__ -     Num steps = 12\n",
      "Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch 0, Dev loss 4.967489719390869\n",
      "Saving model. Best dev so far 4.967489719390869\n",
      "Epoch:   4%|█▍                                   | 1/25 [00:04<01:45,  4.41s/it]Epoch 1, Dev loss 4.6889777183532715\n",
      "Saving model. Best dev so far 4.6889777183532715\n",
      "Epoch:   8%|██▉                                  | 2/25 [00:08<01:42,  4.46s/it]Epoch 2, Dev loss 4.440473556518555\n",
      "Saving model. Best dev so far 4.440473556518555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▍                                | 3/25 [00:13<01:37,  4.42s/it]Epoch 3, Dev loss 4.197568416595459\n",
      "Saving model. Best dev so far 4.197568416595459\n",
      "Epoch:  16%|█████▉                               | 4/25 [00:17<01:32,  4.40s/it]Epoch 4, Dev loss 3.9571709632873535\n",
      "Saving model. Best dev so far 3.9571709632873535\n",
      "Epoch:  20%|███████▍                             | 5/25 [00:21<01:27,  4.38s/it]Epoch 5, Dev loss 3.7468085289001465\n",
      "Saving model. Best dev so far 3.7468085289001465\n",
      "Epoch:  24%|████████▉                            | 6/25 [00:26<01:21,  4.30s/it]Epoch 6, Dev loss 3.5623764991760254\n",
      "Saving model. Best dev so far 3.5623764991760254\n",
      "Epoch:  28%|██████████▎                          | 7/25 [00:30<01:17,  4.31s/it]Epoch 7, Dev loss 3.4305830001831055\n",
      "Saving model. Best dev so far 3.4305830001831055\n",
      "Epoch:  32%|███████████▊                         | 8/25 [00:34<01:13,  4.35s/it]Epoch 8, Dev loss 3.342575788497925\n",
      "Saving model. Best dev so far 3.342575788497925\n",
      "Epoch:  36%|█████████████▎                       | 9/25 [00:39<01:09,  4.34s/it]Epoch 9, Dev loss 3.2823479175567627\n",
      "Saving model. Best dev so far 3.2823479175567627\n",
      "Epoch:  40%|██████████████▍                     | 10/25 [00:43<01:04,  4.31s/it]Epoch 10, Dev loss 3.24044132232666\n",
      "Saving model. Best dev so far 3.24044132232666\n",
      "Epoch:  44%|███████████████▊                    | 11/25 [00:47<01:00,  4.31s/it]Epoch 11, Dev loss 3.2106664180755615\n",
      "Saving model. Best dev so far 3.2106664180755615\n",
      "Epoch:  48%|█████████████████▎                  | 12/25 [00:52<00:56,  4.32s/it]Epoch 12, Dev loss 3.187197685241699\n",
      "Saving model. Best dev so far 3.187197685241699\n",
      "Epoch:  52%|██████████████████▋                 | 13/25 [00:56<00:51,  4.33s/it]Epoch 13, Dev loss 3.167653799057007\n",
      "Saving model. Best dev so far 3.167653799057007\n",
      "Epoch:  56%|████████████████████▏               | 14/25 [01:00<00:47,  4.32s/it]Epoch 14, Dev loss 3.1497902870178223\n",
      "Saving model. Best dev so far 3.1497902870178223\n",
      "Epoch:  60%|█████████████████████▌              | 15/25 [01:05<00:43,  4.33s/it]Epoch 15, Dev loss 3.132920503616333\n",
      "Saving model. Best dev so far 3.132920503616333\n",
      "Epoch:  64%|███████████████████████             | 16/25 [01:09<00:38,  4.31s/it]Epoch 16, Dev loss 3.118053674697876\n",
      "Saving model. Best dev so far 3.118053674697876\n",
      "Epoch:  68%|████████████████████████▍           | 17/25 [01:13<00:34,  4.29s/it]Epoch 17, Dev loss 3.1047399044036865\n",
      "Saving model. Best dev so far 3.1047399044036865\n",
      "Epoch:  72%|█████████████████████████▉          | 18/25 [01:17<00:29,  4.28s/it]Epoch 18, Dev loss 3.094707489013672\n",
      "Saving model. Best dev so far 3.094707489013672\n",
      "Epoch:  76%|███████████████████████████▎        | 19/25 [01:22<00:25,  4.30s/it]Epoch 19, Dev loss 3.087778091430664\n",
      "Saving model. Best dev so far 3.087778091430664\n",
      "Epoch:  80%|████████████████████████████▊       | 20/25 [01:26<00:21,  4.31s/it]Epoch 20, Dev loss 3.084038496017456\n",
      "Saving model. Best dev so far 3.084038496017456\n",
      "Epoch:  84%|██████████████████████████████▏     | 21/25 [01:30<00:17,  4.32s/it]Epoch 21, Dev loss 3.0826382637023926\n",
      "Saving model. Best dev so far 3.0826382637023926\n",
      "Epoch:  88%|███████████████████████████████▋    | 22/25 [01:35<00:12,  4.33s/it]Epoch 22, Dev loss 3.0843923091888428\n",
      "Epoch:  92%|█████████████████████████████████   | 23/25 [01:39<00:08,  4.21s/it]Epoch 23, Dev loss 3.089500665664673\n",
      "Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:43<00:04,  4.12s/it]Epoch 24, Dev loss 3.097972869873047\n",
      "Epoch: 100%|████████████████████████████████████| 25/25 [01:47<00:00,  4.28s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.46s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.03it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.09it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.43it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/bt' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "Namespace(cache='/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE', data_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10', gpu=0, output_dir='/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/bt', sample_num=1, seed=14, task_name='trec', train_batch_size=32)\n",
      "Archive name '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was not found in archive name list. We assumed '/home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/wmt19.en-de.joined-dict.single_model' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 46, in main\n",
      "    backtranslation_using_en_de_model(args)\n",
      "  File \"/home/user/Tae_StudyCode/TransformersDataAugmentation/src/bert_aug/backtranslation.py\", line 69, in backtranslation_using_en_de_model\n",
      "    bpe='fastbpe'\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\", line 174, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/site-packages/fairseq/hub_utils.py\", line 51, in from_pretrained\n",
      "    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\n",
      "  File \"/home/user/anaconda3/envs/tae/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "cat: /home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/bt/bt_aug.tsv: 그런 파일이나 디렉터리가 없습니다\n",
      "Training:   0%|                                           | 0/8 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:11<00:00,  1.39s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:11<00:00,  1.39s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.35s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.35s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.43it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|███████████████████████████████████| 8/8 [00:10<00:00,  1.36s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/cbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 04:39:45 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 04:39:46 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 04:39:46 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 04:39:46 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 04:39:48 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 04:39:48 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   tokens: [CLS] how much electricity does the brain need to work ? [SEP]\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   init_ids: 101 2129 2172 6451 2515 1996 4167 2342 2000 2147 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   input_ids: 101 103 2172 6451 2515 1996 4167 2342 2000 2147 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   masked_lm_labels: -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   tokens: [CLS] when did nixon die ? [SEP]\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   init_ids: 101 2043 2106 11296 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   input_ids: 101 2043 2106 103 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   segment_ids: 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 11296 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   tokens: [CLS] what ' s the difference between j . d . and ll . m . ? [SEP]\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   init_ids: 101 2054 1005 1055 1996 4489 2090 1046 1012 1040 1012 1998 2222 1012 1049 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   input_ids: 101 2054 103 1055 1996 4489 2090 103 103 1040 1012 1998 2222 1012 1049 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   masked_lm_labels: -100 -100 1005 -100 -100 -100 -100 1046 1012 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   tokens: [CLS] what is use ##net for the internet ? [SEP]\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   init_ids: 101 2054 2003 2224 7159 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   input_ids: 101 1996 2003 2224 103 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   segment_ids: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   masked_lm_labels: -100 2054 -100 -100 7159 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:39:48 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 04:39:48 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 04:39:48 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 04:39:48 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:32<00:00, 15.22s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.45s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/cmodbert' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 04:47:02 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 04:47:03 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 04:47:03 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 04:47:03 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 04:47:05 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 04:47:05 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 04:47:05 - INFO - transformers.tokenization_utils -   Adding numeric to the vocabulary\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   tokens: [CLS] numeric how much electricity does the brain need to work ? [SEP]\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   init_ids: 101 30522 2129 2172 6451 2515 1996 4167 2342 2000 2147 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   input_ids: 101 30522 103 2172 6451 2515 1996 4167 2342 2000 2147 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   masked_lm_labels: -100 -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   tokens: [CLS] numeric when did nixon die ? [SEP]\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   init_ids: 101 30522 2043 2106 11296 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   input_ids: 101 30522 2043 2106 103 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 11296 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   tokens: [CLS] description what ' s the difference between j . d . and ll . m . ? [SEP]\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   init_ids: 101 6412 2054 1005 1055 1996 4489 2090 1046 1012 1040 1012 1998 2222 1012 1049 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   input_ids: 101 6412 2054 103 1055 1996 4489 2090 103 103 1040 1012 1998 2222 1012 1049 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 1005 -100 -100 -100 -100 1046 1012 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   tokens: [CLS] description what is use ##net for the internet ? [SEP]\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   init_ids: 101 6412 2054 2003 2224 7159 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   input_ids: 101 6412 1996 2003 2224 103 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 -100 -100 7159 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 04:47:06 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 04:47:06 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 04:47:06 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 04:47:06 - INFO - __main__ -     Num steps = 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                            | 0/150 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|██████████████████████████████████| 150/150 [38:26<00:00, 15.37s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:20<00:00,  1.39s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.06it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.40s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.39it/s]\n",
      "mkdir: `/home/user/Tae_StudyCode/TransformersDataAugmentation/src/utils/datasets/trec/exp_14_10/cmodbertp' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      "05/24/2021 05:29:51 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/24/2021 05:29:52 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/24/2021 05:29:52 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/24/2021 05:29:52 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/user/Tae_StudyCode/TransformersDataAugmentation/CACHE/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/24/2021 05:29:54 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "05/24/2021 05:29:54 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   guid: train-0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   tokens: [CLS] nu ##meric how much electricity does the brain need to work ? [SEP]\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   init_ids: 101 16371 25531 2129 2172 6451 2515 1996 4167 2342 2000 2147 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   input_ids: 101 16371 25531 103 2172 6451 2515 1996 4167 2342 2000 2147 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 2129 -100 -100 -100 -100 -100 -100 -100 -100 1029 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   guid: train-1\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   tokens: [CLS] nu ##meric when did nixon die ? [SEP]\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   init_ids: 101 16371 25531 2043 2106 11296 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   input_ids: 101 16371 25531 2043 2106 103 3280 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 -100 -100 11296 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   label_len: 2\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   guid: dev-0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   tokens: [CLS] description what ' s the difference between j . d . and ll . m . ? [SEP]\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   init_ids: 101 6412 2054 1005 1055 1996 4489 2090 1046 1012 1040 1012 1998 2222 1012 1049 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   input_ids: 101 6412 2054 103 1055 1996 4489 2090 103 103 1040 1012 1998 2222 1012 1049 1012 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   masked_lm_labels: -100 -100 -100 1005 -100 -100 -100 -100 1046 1012 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   *** Example ***\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   guid: dev-1\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   tokens: [CLS] description what is use ##net for the internet ? [SEP]\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   init_ids: 101 6412 2054 2003 2224 7159 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   input_ids: 101 6412 1996 2003 2224 103 2005 1996 4274 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   masked_lm_labels: -100 -100 2054 -100 -100 7159 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   label_len: 1\n",
      "05/24/2021 05:29:54 - INFO - __main__ -   ***** Running training *****\n",
      "05/24/2021 05:29:54 - INFO - __main__ -     Num examples = 60\n",
      "05/24/2021 05:29:54 - INFO - __main__ -     Batch size = 8\n",
      "05/24/2021 05:29:54 - INFO - __main__ -     Num steps = 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [02:31<00:00, 15.17s/it]\n",
      "Training:   0%|                                          | 0/15 [00:00<?, ?it/s]/tmp/pip-req-build-w9kte7xz/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.45s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.44s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.41it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.37it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.43s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.42it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.08it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.41s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.38it/s]\n",
      "Evaluating test set: 100%|██████████████████████| 63/63 [00:20<00:00,  3.07it/s]\n",
      "Training: 100%|█████████████████████████████████| 15/15 [00:21<00:00,  1.42s/it]\n",
      "Evaluating dev set: 100%|█████████████████████████| 8/8 [00:02<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "!bash bert_trec_lower.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d6c49",
   "metadata": {},
   "source": [
    "### nltk 패키지가 없어서 설치하였음(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2533b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: click in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from nltk) (4.42.1)\n",
      "Requirement already satisfied: regex in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: joblib in /home/user/anaconda3/envs/hs/lib/python3.7/site-packages (from nltk) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7c017ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> l\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
      "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [ ] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "Hit Enter to continue: all_corpora\n",
      "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
      "                           and Basque Subset)\n",
      "  [ ] crubadan............ Crubadan Corpus\n",
      "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
      "  [ ] dolch............... Dolch Word List\n",
      "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
      "                           Corpus\n",
      "  [ ] floresta............ Portuguese Treebank\n",
      "  [ ] framenet_v15........ FrameNet 1.5\n",
      "  [ ] framenet_v17........ FrameNet 1.7\n",
      "  [ ] gazetteers.......... Gazeteer Lists\n",
      "  [ ] genesis............. Genesis Corpus\n",
      "  [ ] gutenberg........... Project Gutenberg Selections\n",
      "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
      "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
      "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
      "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
      "                           ChaSen format)\n",
      "  [ ] kimmo............... PC-KIMMO Data Files\n",
      "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
      "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
      "                           for parser comparison\n",
      "Hit Enter to continue: all\n",
      "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
      "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
      "                           part-of-speech tags\n",
      "  [ ] machado............. Machado de Assis -- Obra Completa\n",
      "  [ ] masc_tagged......... MASC Tagged Corpus\n",
      "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
      "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
      "  [ ] moses_sample........ Moses Sample Models\n",
      "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
      "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
      "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
      "                           2015) subset of the Paraphrase Database.\n",
      "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
      "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
      "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
      "  [ ] nps_chat............ NPS Chat\n",
      "  [ ] omw................. Open Multilingual Wordnet\n",
      "  [ ] opinion_lexicon..... Opinion Lexicon\n",
      "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
      "  [ ] paradigms........... Paradigm Corpus\n",
      "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
      "                           Evaluation Shared Task\n",
      "Hit Enter to continue: \n",
      "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
      "                           character properties in Perl\n",
      "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
      "  [ ] pl196x.............. Polish language of the XX century sixties\n",
      "  [ ] porter_test......... Porter Stemmer Test Files\n",
      "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
      "  [ ] problem_reports..... Problem Report Corpus\n",
      "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
      "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
      "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
      "  [ ] pros_cons........... Pros and Cons\n",
      "  [ ] ptb................. Penn Treebank\n",
      "  [ ] qc.................. Experimental Data for Question Classification\n",
      "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
      "                           version\n",
      "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
      "                           Portuguesa)\n",
      "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
      "  [ ] sample_grammars..... Sample Grammars\n",
      "  [ ] semcor.............. SemCor 3.0\n",
      "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
      "Hit Enter to continue: x\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> x\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> l\n",
      "\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
      "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [ ] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "Hit Enter to continue: x\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5573a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "print(nltk.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
