# Text Augmentation using by BERT model
Keyword : #NLP, #BERT, #TextAugmentation, #DataAugmentation

---
---
## Abstract

* This code is originally released from amazon-research package (https://github.com/amazon-research/transformers-data-augmentation) In the paper, we mentioned https://github.com/varinf/TransformersDataAugmentation url so we are providing a copy of the same code here.

* Code associated with the Data Augmentation using Pre-trained Transformer Models paper

* Code contains implementation of the following data augmentation methods

  - EDA (Baseline)
  - Backtranslation (Baseline)
  - CBERT (Baseline)


---
---
## DataSets

* I used a dataset from following resource to test augmentationing code using by bert.
  - TREC : https://github.com/1024er/cbert_aug/tree/crayon/datasets/TREC
  - Augmentationing code : https://github.com/varinf/TransformersDataAugmentation

* Low-data setup
  - L2+L3 DataSets : For students who speak Korean as first language, 영어를 제 2언어로 
  - <Private>




.
